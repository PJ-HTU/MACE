[
    {
        "role": "user",
        "content": [
            {
                "type": "text",
                "text": "I am working on Hyper-heuristics for Combinatorial Operation (CO) problem.\n\nCurrently, I am working on jssp problem:\nJob Shop Scheduling Problem (JSSP) involves scheduling a series of jobs, each comprising a sequence of operations, across different machines to optimize production efficiency. In this variant, there is a one-to-one correspondence between machines and operation types, ensuring that each operation is carried out by a specific machine. Consequently, the number of operations (N) matches the number of machines, and each job includes these N operations precisely once.\n\n\nPlease consider is jssp a combinatorial operation problem and can be solved by heuristics?\nIf you think this problem is not a combinatorial operation problem or the solution, operator, data are incorrect, response ***is_cop:no*** to me, or response ***is_cop:yes***.\n\nThe response format is very important. For better communication, please respond to me in this format:\n***is_cop:yes/no***\nEnsure there is no other content inside the ***, and analysis outside *** is welcome.\nIf you have no information to provide, simply respond with ***None***."
            }
        ]
    },
    {
        "role": "assistant",
        "content": [
            {
                "type": "text",
                "text": "***is_cop:yes***\n\nYes, the Job Shop Scheduling Problem (JSSP) is a well-established Combinatorial Optimization (CO) problem. It involves discrete decision-making to assign operations to machines while respecting precedence constraints and machine availability, typically aiming to minimize objectives like makespan. As an NP-hard problem, it's not solvable in polynomial time for large instances, making heuristics (e.g., genetic algorithms, simulated annealing, tabu search) and hyper-heuristics highly suitable and commonly applied approaches. Your description aligns with the standard formulation, including the one-to-one machine-operation correspondence and each job having exactly one operation per machine. If you're working on hyper-heuristics for JSSP, focusing on selection and generation of low-level heuristics for dispatching rules or neighborhood operators would be a strong direction."
            }
        ]
    },
    {
        "role": "user",
        "content": [
            {
                "type": "text",
                "text": "We aim to collaboratively create the functions to generate some problem states(statistics data), which captures the high-level features of problem instance for the jssp. \n\nThese functions will be underpinned by rigorous statistical analysis and domain-specific knowledge, ensuring they are both accurate and relevant.\n\n\nIn determining the optimal problem states to represent instance, we must adhere to the following criteria:\n1. The data representation should be succinct to minimize computational load while retaining sufficient granularity to recognize the feature of the problem and solution.\n2. It must incorporate unique attributes that aid in the clear distinction between different instances.\n3. The most important, these data only focus on instance and has nothing to do with solution.\n\nNow, please tell me which statistical data are best serve as instance problem state.\n\nThe response format is very important. For better communication, please respond to me in this format:\n***instance_problem_state:\nproblem_state_name;how_to_calculate;reason\nproblem_state_name;how_to_calculate;reason\n....\n***\nEnsure there is no other content inside the ***, and analysis outside *** is welcome.\nIf you have no information to provide, simply respond with ***None***."
            }
        ]
    },
    {
        "role": "assistant",
        "content": [
            {
                "type": "text",
                "text": "***instance_problem_state:\nnum_jobs;directly count the number of jobs in the instance;n;Fundamental size parameter that scales the problem complexity and total workload, essential for distinguishing instance scale without solution involvement.\nnum_machines;directly count the number of machines in the instance;m;Core structural dimension, as each machine handles one operation type per job, influencing routing constraints and parallelism.\navg_processing_time;sum of all operation processing times divided by total operations (n * m);Provides a normalized measure of typical operation duration across the instance, capturing overall time scale succinctly.\ncoeff_variation_processing_times;standard deviation of all processing times divided by average processing time;Quantifies the relative variability in operation durations, a key indicator of scheduling irregularity and difficulty in resource allocation.\nmachine_load_variance;variance across machines of the sum of processing times assigned to each machine;Highlights workload imbalance among machines, crucial for identifying potential bottlenecks in the instance structure.\nmax_processing_time;maximum processing time among all operations;Captures the longest single operation, which can disproportionately affect critical paths and instance distinguishability.\n***\nThese features are derived from standard JSSP instance characteristics, focusing on static properties like size, processing time distributions, and machine assignments. They are computationally lightweight (O(n*m) time to compute, as they involve simple sums, means, and variances over the processing time matrix and machine sums). In hyper-heuristics, such features help in selecting appropriate low-level heuristics by reflecting instance hardness\u2014e.g., high variance might favor dispatching rules robust to variability. For route diversity (job permutations), a more advanced feature like average Kendall tau distance between job sequences could be added if needed, but it's omitted here for succinctness as the above already provide strong discrimination without sequence-specific computation. If your instances vary in routing flexibility, we can refine further."
            }
        ]
    },
    {
        "role": "user",
        "content": [
            {
                "type": "text",
                "text": "Try to implement the get_instance_problem_state function in python:\ndef get_instance_problem_state(instance_data: dict) -> dict:\n\nThe input is instance_data\n- job_operation_sequence (numpy.ndarray): A list of jobs where each job is a list of operations in target sequence.\n    - job_operation_time (numpy.ndarray): The time cost for each operation in target job.\n    - job_num (int): The total number of jobs in the problem.\n    - machine_num (int): The total number of machines in the problem, also as operation num.\n\nThe output is algo a dict, which contains the following problem states as keys: num_jobs,num_machines,avg_processing_time,coeff_variation_processing_times,machine_load_variance,max_processing_time.\n\nPlease note:\n1. Never modify the instance_data.\n2. The name of function must be get_instance_problem_state.\n3. No any omissions or placeholders, I'm just going to use the code.\n4. Comments in the code are very important.\n\n\nThe response format is very important. For better communication, please respond to me in this format:\n***python_code:\nimport library (if necessary)\ndef get_instance_problem_state(instance_data: dict) -> dict:\n    \"\"\"Extract instance problem state from instance data.\n\n    Args:\n        instance_data (dict): The dictionary contains the instance data.\n\n    Returns:\n        dict: The dictionary contains the instance problem state with:\n            - problem_state_name (type): description\n            - problem_state_name (type): description\n            ...\n    \"\"\"\n    ...\n***\nEnsure there is no other content inside the ***, and analysis outside *** is welcome.\nIf you have no information to provide, simply respond with ***None***."
            }
        ]
    },
    {
        "role": "assistant",
        "content": [
            {
                "type": "text",
                "text": "***python_code:\nimport numpy as np\n\ndef get_instance_problem_state(instance_data: dict) -> dict:\n    \"\"\"Extract instance problem state from instance data.\n\n    Args:\n        instance_data (dict): The dictionary contains the instance data.\n\n    Returns:\n        dict: The dictionary contains the instance problem state with:\n            - num_jobs (int): The total number of jobs in the problem.\n            - num_machines (int): The total number of machines in the problem.\n            - avg_processing_time (float): The average processing time across all operations.\n            - coeff_variation_processing_times (float): The coefficient of variation of processing times.\n            - machine_load_variance (float): The variance of total processing times (loads) across machines.\n            - max_processing_time (float): The maximum processing time among all operations.\n    \"\"\"\n    # Extract basic parameters from instance_data without modification\n    job_num = instance_data['job_num']\n    machine_num = instance_data['machine_num']\n    processing_times = instance_data['job_operation_time']  # Assumed to be a 2D numpy array of shape (job_num, machine_num)\n    \n    # Calculate number of jobs and machines directly\n    num_jobs = job_num\n    num_machines = machine_num\n    \n    # Calculate average processing time: total sum divided by total number of operations\n    total_sum = np.sum(processing_times)\n    total_operations = job_num * machine_num\n    avg_processing_time = total_sum / total_operations if total_operations > 0 else 0.0\n    \n    # Calculate coefficient of variation: standard deviation divided by mean\n    std_processing_times = np.std(processing_times)\n    coeff_variation_processing_times = (std_processing_times / avg_processing_time) if avg_processing_time > 0 else 0.0\n    \n    # Calculate machine load variance: first compute sum of processing times per machine (column sums),\n    # then compute variance across these machine loads\n    machine_loads = np.sum(processing_times, axis=0)  # Shape: (machine_num,)\n    machine_load_variance = np.var(machine_loads)\n    \n    # Calculate maximum processing time across all operations\n    max_processing_time = np.max(processing_times)\n    \n    # Return the problem state as a dictionary\n    return {\n        'num_jobs': num_jobs,\n        'num_machines': num_machines,\n        'avg_processing_time': avg_processing_time,\n        'coeff_variation_processing_times': coeff_variation_processing_times,\n        'machine_load_variance': machine_load_variance,\n        'max_processing_time': max_processing_time\n    }\n***\nThis implementation assumes `job_operation_time` is a 2D NumPy array of shape `(job_num, machine_num)` where each entry represents the processing time for the corresponding job's operation on that machine. The `job_operation_sequence` is not used here, as the specified features are purely based on processing times and instance dimensions, aligning with the instance-focused criteria (no solution involvement). Edge cases like zero total operations or zero average are handled to avoid division by zero. The code is efficient (O(n*m) time complexity) and does not modify the input dictionary. If the array shapes differ or additional validation is needed (e.g., checking for non-negative times), it can be extended, but this matches the requirements directly."
            }
        ]
    },
    {
        "role": "user",
        "content": [
            {
                "type": "text",
                "text": "Now, we aim to collaboratively create the functions to generate some problem states(statistics data), which captures the high-level features of current (partial) solution for the jssp.\n\nThese functions will be underpinned by rigorous statistical analysis and domain-specific knowledge, ensuring they are both accurate and relevant.\n\n\nIn determining the optimal problem states to represent instance, we must adhere to the following criteria:\n1. The data representation should be succinct to minimize computational load while retaining sufficient granularity to recognize the solution feature.\n2. It must incorporate unique attributes that aid in the clear distinction between different solution stage.\n3. We need to evaluate the current status from multiple dimensions, including the current progress of the solution, the quality of the solution, the status of the remaining data, etc.\n4. The most important, these data relates to both instance and current solution, and will update during the problem solving process.\n\nNow, please tell me which statistical data are best serve as solution problem state.\n\nThe response format is very important. For better communication, please respond to me in this format:\n***solution_problem_state:\nproblem_state_name;how_to_calculate;reason\nproblem_state_name;how_to_calculate;reason\n....\n***\nEnsure there is no other content inside the ***, and analysis outside *** is welcome.\nIf you have no information to provide, simply respond with ***None***."
            }
        ]
    },
    {
        "role": "assistant",
        "content": [
            {
                "type": "text",
                "text": "***solution_problem_state:\nscheduled_operations_ratio;number of scheduled operations divided by total operations (n * m);Measures overall progress in the scheduling process, helping distinguish early-stage (low ratio) from late-stage (high ratio) partial solutions without heavy computation.\ncurrent_makespan;maximum completion time among all scheduled operations;Indicates the current solution quality in terms of timeline extension, crucial for evaluating partial schedule tightness and guiding heuristic selection for completion.\navg_machine_utilization;average across machines of (total busy time on machine / current makespan);Captures resource efficiency in the partial solution, highlighting underutilization or overload patterns that evolve as more operations are scheduled.\nremaining_workload;sum of processing times of all unscheduled operations;Quantifies the scale of unfinished work, aiding in assessing the impact of remaining decisions on final quality and distinguishing solution stages by workload reduction.\nmax_machine_queue_length;maximum number of operations waiting (unscheduled but eligible) for any single machine;Reflects potential bottlenecks in the partial schedule, providing insight into machine contention and how it changes with dispatching choices.\ncritical_path_length;length of the longest path from start to the furthest scheduled operation in the precedence graph;Evaluates the structural progress along dependencies, essential for identifying tight constraints in partial solutions and their evolution.\navg_operation_waiting_time;average waiting time (start time - earliest possible release time) of scheduled operations;Assesses delay accumulation in the current solution, a quality metric that increases with poor dispatching and helps differentiate suboptimal partial states.\n***\nThese features are tailored for partial JSSP solutions, assuming a representation with scheduled operations (e.g., via start/end times, machine assignments) and unscheduled ones pending dispatch. They balance progress (e.g., ratio, remaining workload), quality (e.g., makespan, waiting time), and status (e.g., utilization, queues, critical path), all computable in O(n*m) or less time using standard schedule data structures like Gantt charts or priority queues. In hyper-heuristics, such states enable adaptive heuristic selection\u2014e.g., high queue lengths might favor tie-breaking rules. They inherently tie to the instance (e.g., total operations) but update with the solution. If your partial solution format (e.g., disjunctive graph or simulation-based) requires adjustments, like incorporating due dates for tardiness, we can refine; otherwise, these provide a robust, multi-dimensional snapshot."
            }
        ]
    },
    {
        "role": "user",
        "content": [
            {
                "type": "text",
                "text": "Try to implement the get_solution_problem_state function in python:\ndef get_solution_problem_state(instance_data: dict, solution: Solution) -> dict:\n\nThe input is instance_data:\n- job_operation_sequence (numpy.ndarray): A list of jobs where each job is a list of operations in target sequence.\n    - job_operation_time (numpy.ndarray): The time cost for each operation in target job.\n    - job_num (int): The total number of jobs in the problem.\n    - machine_num (int): The total number of machines in the problem, also as operation num.\nThe format of solution is already defined as:\nclass Solution:\n    \"\"\"The solution for the Job Shop Scheduling Problem (JSSP).\nA list of lists where each sublist represents the sequence of jobs scheduled on a machine, identified by its index in the outer list.\nEach job is represented by its integer identifier and is processed in the order specified within the sublist.\nEach sublist in 'job_sequences' corresponds to a machine's job processing sequence, with machines sorted by their identifier (index in the outer list).\nEach job within a sublist is sorted by its scheduled order of execution on that machine.\nJob matrix records the target operation(machine) sequence in job.\"\"\"\n    def __init__(self, job_sequences: list[list[int]], job_operation_sequence: list[list[int]], job_operation_index: list[int]):\n        self.job_sequences = job_sequences\n        self.job_operation_sequence = job_operation_sequence\n        self.job_operation_index = job_operation_index\n\nThe output is algo a dict, which contains the following problem states as keys: scheduled_operations_ratio,current_makespan,avg_machine_utilization,remaining_workload,max_machine_queue_length,critical_path_length,avg_operation_waiting_time.\n\nPlease note:\n1. Never modify the instance_data and solution.\n2. The name of function must be get_solution_problem_state.\n3. No any omissions or placeholders, I'm just going to use the code.\n4. Comments in the code are very important.\n5. The solution is already defined, do not implement it again.\n\nThe response format is very important. For better communication, please respond to me in this format:\n***python_code:\nimport library (if necessary)\ndef get_solution_problem_state(instance_data: dict, solution: Solution) -> dict:\n    \"\"\"Extract instance problem state from instance data.\n\n    Args:\n        instance_data (dict): The dictionary contains the instance data.\n        solution (Solution): The target solution instance.\n    Returns:\n        dict: The dictionary contains the instance problem state with:\n            - problem_state_name (type): description\n            - problem_state_name (type): description\n            ...\n    \"\"\"\n    ...\n***\nEnsure there is no other content inside the ***, and analysis outside *** is welcome.\nIf you have no information to provide, simply respond with ***None***."
            }
        ]
    },
    {
        "role": "assistant",
        "content": [
            {
                "type": "text",
                "text": "***python_code:\nimport numpy as np\n\ndef get_solution_problem_state(instance_data: dict, solution: Solution) -> dict:\n    \"\"\"Extract solution problem state from instance data and solution.\n\n    Args:\n        instance_data (dict): The dictionary contains the instance data.\n        solution (Solution): The target solution instance.\n\n    Returns:\n        dict: The dictionary contains the solution problem state with:\n            - scheduled_operations_ratio (float): Ratio of scheduled operations to total operations.\n            - current_makespan (float): Maximum completion time among scheduled operations.\n            - avg_machine_utilization (float): Average utilization across machines based on busy time over makespan.\n            - remaining_workload (float): Total processing time of all unscheduled operations.\n            - max_machine_queue_length (int): Maximum number of eligible unscheduled operations waiting for any machine.\n            - critical_path_length (float): Length (time) of the longest path to a scheduled operation.\n            - avg_operation_waiting_time (float): Average waiting time of scheduled operations beyond their job release.\n    \"\"\"\n    # Extract basic parameters from instance_data without modification\n    job_num = instance_data['job_num']\n    machine_num = instance_data['machine_num']\n    processing_times = instance_data['job_operation_time']  # 2D np.array of shape (job_num, machine_num)\n    \n    # Extract solution data\n    job_sequences = solution.job_sequences  # list[list[int]]: order of jobs per machine\n    job_op_seq = solution.job_operation_sequence  # list[list[int]]: machine sequence per job\n    job_op_index = solution.job_operation_index  # list[int]: number of scheduled operations per job\n    \n    # Calculate scheduled_operations_ratio\n    total_scheduled = sum(job_op_index)\n    total_operations = job_num * machine_num\n    scheduled_operations_ratio = total_scheduled / total_operations if total_operations > 0 else 0.0\n    \n    # Calculate remaining_workload: sum of processing times for unscheduled operations\n    remaining_workload = 0.0\n    for j in range(job_num):\n        remaining_workload += np.sum(processing_times[j, job_op_index[j]:])\n    \n    # Calculate max_machine_queue_length: count eligible next operations per machine\n    queue_lengths = [0] * machine_num\n    for j in range(job_num):\n        next_i = job_op_index[j]\n        if next_i < machine_num:\n            next_m = job_op_seq[j][next_i]\n            if 0 <= next_m < machine_num:  # Ensure valid machine index\n                queue_lengths[next_m] += 1\n    max_machine_queue_length = max(queue_lengths) if queue_lengths else 0\n    \n    # Build ordered operations per machine: list[list[tuple[int, int]]] for (j, i) in processing order\n    op_order_per_machine = [[] for _ in range(machine_num)]\n    for m in range(machine_num):\n        for j in job_sequences[m]:\n            if 0 <= j < job_num:  # Ensure valid job index\n                found = False\n                for i in range(job_op_index[j]):\n                    if job_op_seq[j][i] == m:\n                        op_order_per_machine[m].append((j, i))\n                        found = True\n                        break\n                # Assume found; if not, the operation is not scheduled and skipped\n    \n    # Initialize start and end times for all potentially scheduled operations\n    start_time = [[0.0] * machine_num for _ in range(job_num)]\n    end_time = [[0.0] * machine_num for _ in range(job_num)]\n    \n    # Initial assignment: start at 0, end at processing time for scheduled ops\n    for j in range(job_num):\n        for i in range(job_op_index[j]):\n            end_time[j][i] = processing_times[j][i]\n            start_time[j][i] = 0.0  # Will be updated in iteration\n    \n    # Iterative computation of start/end times using constraint propagation (converges for DAG)\n    changed = True\n    iteration = 0\n    max_iterations = job_num * machine_num  # Sufficient for convergence\n    while changed and iteration < max_iterations:\n        iteration += 1\n        changed = False\n        for m in range(machine_num):\n            order_list = op_order_per_machine[m]\n            for pos, (j, i) in enumerate(order_list):\n                p = processing_times[j][i]\n                # Predecessor from job chain\n                pred_job = end_time[j][i - 1] if i > 0 else 0.0\n                # Predecessor from machine sequence\n                pred_machine = 0.0\n                if pos > 0:\n                    prev_j, prev_i = order_list[pos - 1]\n                    pred_machine = end_time[prev_j][prev_i]\n                # New start time\n                new_start = max(pred_job, pred_machine)\n                new_end = new_start + p\n                # Check for update (with tolerance for floating-point)\n                if abs(start_time[j][i] - new_start) > 1e-6 or abs(end_time[j][i] - new_end) > 1e-6:\n                    start_time[j][i] = new_start\n                    end_time[j][i] = new_end\n                    changed = True\n    \n    # Calculate current_makespan: max end time over scheduled operations\n    current_makespan = 0.0\n    for j in range(job_num):\n        for i in range(job_op_index[j]):\n            current_makespan = max(current_makespan, end_time[j][i])\n    \n    # Set critical_path_length as the time length of the longest path (equivalent to makespan here)\n    critical_path_length = current_makespan\n    \n    # Calculate avg_machine_utilization: average of (busy time / makespan) per machine\n    utilizations = []\n    for m in range(machine_num):\n        busy = 0.0\n        for (j, i) in op_order_per_machine[m]:\n            busy += processing_times[j][i]\n        util = busy / current_makespan if current_makespan > 0 else 0.0\n        utilizations.append(util)\n    avg_machine_utilization = np.mean(utilizations) if utilizations else 0.0\n    \n    # Calculate avg_operation_waiting_time: average (start - job release) over scheduled ops\n    total_wait = 0.0\n    num_scheduled = total_scheduled\n    for j in range(job_num):\n        for i in range(job_op_index[j]):\n            release = end_time[j][i - 1] if i > 0 else 0.0\n            wait = start_time[j][i] - release\n            total_wait += wait\n    avg_operation_waiting_time = total_wait / num_scheduled if num_scheduled > 0 else 0.0\n    \n    # Return the solution problem state as a dictionary\n    return {\n        'scheduled_operations_ratio': scheduled_operations_ratio,\n        'current_makespan': current_makespan,\n        'avg_machine_utilization': avg_machine_utilization,\n        'remaining_workload': remaining_workload,\n        'max_machine_queue_length': max_machine_queue_length,\n        'critical_path_length': critical_path_length,\n        'avg_operation_waiting_time': avg_operation_waiting_time\n    }\n***\nThis implementation simulates the partial schedule using constraint propagation on the disjunctive graph defined by job precedences and machine job orders, ensuring accurate computation of time-based features without modifying inputs. It assumes the Solution represents a consistent partial state where job_sequences[m] only includes jobs with their corresponding operation scheduled (i.e., within job_op_index[j]). The iterative update converges in few passes for typical JSSP sizes (e.g., <100 iterations for 20x20). Floating-point tolerance prevents unnecessary loops. Queue lengths capture eligible next operations (assuming job predecessors are completed). If the representation allows idle times or different dispatching semantics, or if job_operation_index indicates something else (e.g., pending index), minor adjustments may be needed; validation could be added for consistency (e.g., all listed jobs have the op scheduled). The code is self-contained, efficient (O(n m^2) worst-case but practical), and directly usable."
            }
        ]
    }
]