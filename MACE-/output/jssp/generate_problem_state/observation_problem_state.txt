user
I am working on Hyper-heuristics for Combinatorial Operation (CO) problem.

Currently, I am working on jssp problem:
Job Shop Scheduling Problem (JSSP) involves scheduling a series of jobs, each comprising a sequence of operations, across different machines to optimize production efficiency. In this variant, there is a one-to-one correspondence between machines and operation types, ensuring that each operation is carried out by a specific machine. Consequently, the number of operations (N) matches the number of machines, and each job includes these N operations precisely once.


Please consider is jssp a combinatorial operation problem and can be solved by heuristics?
If you think this problem is not a combinatorial operation problem or the solution, operator, data are incorrect, response ***is_cop:no*** to me, or response ***is_cop:yes***.

The response format is very important. For better communication, please respond to me in this format:
***is_cop:yes/no***
Ensure there is no other content inside the ***, and analysis outside *** is welcome.
If you have no information to provide, simply respond with ***None***.
------------------------------------------------------------------------------------

assistant
***is_cop:yes***

Yes, the Job Shop Scheduling Problem (JSSP) is a well-established Combinatorial Optimization (CO) problem. It involves discrete decision-making to assign operations to machines while respecting precedence constraints and machine availability, typically aiming to minimize objectives like makespan. As an NP-hard problem, it's not solvable in polynomial time for large instances, making heuristics (e.g., genetic algorithms, simulated annealing, tabu search) and hyper-heuristics highly suitable and commonly applied approaches. Your description aligns with the standard formulation, including the one-to-one machine-operation correspondence and each job having exactly one operation per machine. If you're working on hyper-heuristics for JSSP, focusing on selection and generation of low-level heuristics for dispatching rules or neighborhood operators would be a strong direction.
------------------------------------------------------------------------------------

user
We aim to collaboratively create the functions to generate some problem states(statistics data), which captures the high-level features of problem instance for the jssp. 

These functions will be underpinned by rigorous statistical analysis and domain-specific knowledge, ensuring they are both accurate and relevant.


In determining the optimal problem states to represent instance, we must adhere to the following criteria:
1. The data representation should be succinct to minimize computational load while retaining sufficient granularity to recognize the feature of the problem and solution.
2. It must incorporate unique attributes that aid in the clear distinction between different instances.
3. The most important, these data only focus on instance and has nothing to do with solution.

Now, please tell me which statistical data are best serve as instance problem state.

The response format is very important. For better communication, please respond to me in this format:
***instance_problem_state:
problem_state_name;how_to_calculate;reason
problem_state_name;how_to_calculate;reason
....
***
Ensure there is no other content inside the ***, and analysis outside *** is welcome.
If you have no information to provide, simply respond with ***None***.
------------------------------------------------------------------------------------

assistant
***instance_problem_state:
num_jobs;directly count the number of jobs in the instance;n;Fundamental size parameter that scales the problem complexity and total workload, essential for distinguishing instance scale without solution involvement.
num_machines;directly count the number of machines in the instance;m;Core structural dimension, as each machine handles one operation type per job, influencing routing constraints and parallelism.
avg_processing_time;sum of all operation processing times divided by total operations (n * m);Provides a normalized measure of typical operation duration across the instance, capturing overall time scale succinctly.
coeff_variation_processing_times;standard deviation of all processing times divided by average processing time;Quantifies the relative variability in operation durations, a key indicator of scheduling irregularity and difficulty in resource allocation.
machine_load_variance;variance across machines of the sum of processing times assigned to each machine;Highlights workload imbalance among machines, crucial for identifying potential bottlenecks in the instance structure.
max_processing_time;maximum processing time among all operations;Captures the longest single operation, which can disproportionately affect critical paths and instance distinguishability.
***
These features are derived from standard JSSP instance characteristics, focusing on static properties like size, processing time distributions, and machine assignments. They are computationally lightweight (O(n*m) time to compute, as they involve simple sums, means, and variances over the processing time matrix and machine sums). In hyper-heuristics, such features help in selecting appropriate low-level heuristics by reflecting instance hardness—e.g., high variance might favor dispatching rules robust to variability. For route diversity (job permutations), a more advanced feature like average Kendall tau distance between job sequences could be added if needed, but it's omitted here for succinctness as the above already provide strong discrimination without sequence-specific computation. If your instances vary in routing flexibility, we can refine further.
------------------------------------------------------------------------------------

user
Try to implement the get_instance_problem_state function in python:
def get_instance_problem_state(instance_data: dict) -> dict:

The input is instance_data
- job_operation_sequence (numpy.ndarray): A list of jobs where each job is a list of operations in target sequence.
    - job_operation_time (numpy.ndarray): The time cost for each operation in target job.
    - job_num (int): The total number of jobs in the problem.
    - machine_num (int): The total number of machines in the problem, also as operation num.

The output is algo a dict, which contains the following problem states as keys: num_jobs,num_machines,avg_processing_time,coeff_variation_processing_times,machine_load_variance,max_processing_time.

Please note:
1. Never modify the instance_data.
2. The name of function must be get_instance_problem_state.
3. No any omissions or placeholders, I'm just going to use the code.
4. Comments in the code are very important.


The response format is very important. For better communication, please respond to me in this format:
***python_code:
import library (if necessary)
def get_instance_problem_state(instance_data: dict) -> dict:
    """Extract instance problem state from instance data.

    Args:
        instance_data (dict): The dictionary contains the instance data.

    Returns:
        dict: The dictionary contains the instance problem state with:
            - problem_state_name (type): description
            - problem_state_name (type): description
            ...
    """
    ...
***
Ensure there is no other content inside the ***, and analysis outside *** is welcome.
If you have no information to provide, simply respond with ***None***.
------------------------------------------------------------------------------------

assistant
***python_code:
import numpy as np

def get_instance_problem_state(instance_data: dict) -> dict:
    """Extract instance problem state from instance data.

    Args:
        instance_data (dict): The dictionary contains the instance data.

    Returns:
        dict: The dictionary contains the instance problem state with:
            - num_jobs (int): The total number of jobs in the problem.
            - num_machines (int): The total number of machines in the problem.
            - avg_processing_time (float): The average processing time across all operations.
            - coeff_variation_processing_times (float): The coefficient of variation of processing times.
            - machine_load_variance (float): The variance of total processing times (loads) across machines.
            - max_processing_time (float): The maximum processing time among all operations.
    """
    # Extract basic parameters from instance_data without modification
    job_num = instance_data['job_num']
    machine_num = instance_data['machine_num']
    processing_times = instance_data['job_operation_time']  # Assumed to be a 2D numpy array of shape (job_num, machine_num)
    
    # Calculate number of jobs and machines directly
    num_jobs = job_num
    num_machines = machine_num
    
    # Calculate average processing time: total sum divided by total number of operations
    total_sum = np.sum(processing_times)
    total_operations = job_num * machine_num
    avg_processing_time = total_sum / total_operations if total_operations > 0 else 0.0
    
    # Calculate coefficient of variation: standard deviation divided by mean
    std_processing_times = np.std(processing_times)
    coeff_variation_processing_times = (std_processing_times / avg_processing_time) if avg_processing_time > 0 else 0.0
    
    # Calculate machine load variance: first compute sum of processing times per machine (column sums),
    # then compute variance across these machine loads
    machine_loads = np.sum(processing_times, axis=0)  # Shape: (machine_num,)
    machine_load_variance = np.var(machine_loads)
    
    # Calculate maximum processing time across all operations
    max_processing_time = np.max(processing_times)
    
    # Return the problem state as a dictionary
    return {
        'num_jobs': num_jobs,
        'num_machines': num_machines,
        'avg_processing_time': avg_processing_time,
        'coeff_variation_processing_times': coeff_variation_processing_times,
        'machine_load_variance': machine_load_variance,
        'max_processing_time': max_processing_time
    }
***
This implementation assumes `job_operation_time` is a 2D NumPy array of shape `(job_num, machine_num)` where each entry represents the processing time for the corresponding job's operation on that machine. The `job_operation_sequence` is not used here, as the specified features are purely based on processing times and instance dimensions, aligning with the instance-focused criteria (no solution involvement). Edge cases like zero total operations or zero average are handled to avoid division by zero. The code is efficient (O(n*m) time complexity) and does not modify the input dictionary. If the array shapes differ or additional validation is needed (e.g., checking for non-negative times), it can be extended, but this matches the requirements directly.
------------------------------------------------------------------------------------

user
Now, we aim to collaboratively create the functions to generate some problem states(statistics data), which captures the high-level features of current (partial) solution for the jssp.

These functions will be underpinned by rigorous statistical analysis and domain-specific knowledge, ensuring they are both accurate and relevant.


In determining the optimal problem states to represent instance, we must adhere to the following criteria:
1. The data representation should be succinct to minimize computational load while retaining sufficient granularity to recognize the solution feature.
2. It must incorporate unique attributes that aid in the clear distinction between different solution stage.
3. We need to evaluate the current status from multiple dimensions, including the current progress of the solution, the quality of the solution, the status of the remaining data, etc.
4. The most important, these data relates to both instance and current solution, and will update during the problem solving process.

Now, please tell me which statistical data are best serve as solution problem state.

The response format is very important. For better communication, please respond to me in this format:
***solution_problem_state:
problem_state_name;how_to_calculate;reason
problem_state_name;how_to_calculate;reason
....
***
Ensure there is no other content inside the ***, and analysis outside *** is welcome.
If you have no information to provide, simply respond with ***None***.
------------------------------------------------------------------------------------

assistant
***solution_problem_state:
scheduled_operations_ratio;number of scheduled operations divided by total operations (n * m);Measures overall progress in the scheduling process, helping distinguish early-stage (low ratio) from late-stage (high ratio) partial solutions without heavy computation.
current_makespan;maximum completion time among all scheduled operations;Indicates the current solution quality in terms of timeline extension, crucial for evaluating partial schedule tightness and guiding heuristic selection for completion.
avg_machine_utilization;average across machines of (total busy time on machine / current makespan);Captures resource efficiency in the partial solution, highlighting underutilization or overload patterns that evolve as more operations are scheduled.
remaining_workload;sum of processing times of all unscheduled operations;Quantifies the scale of unfinished work, aiding in assessing the impact of remaining decisions on final quality and distinguishing solution stages by workload reduction.
max_machine_queue_length;maximum number of operations waiting (unscheduled but eligible) for any single machine;Reflects potential bottlenecks in the partial schedule, providing insight into machine contention and how it changes with dispatching choices.
critical_path_length;length of the longest path from start to the furthest scheduled operation in the precedence graph;Evaluates the structural progress along dependencies, essential for identifying tight constraints in partial solutions and their evolution.
avg_operation_waiting_time;average waiting time (start time - earliest possible release time) of scheduled operations;Assesses delay accumulation in the current solution, a quality metric that increases with poor dispatching and helps differentiate suboptimal partial states.
***
These features are tailored for partial JSSP solutions, assuming a representation with scheduled operations (e.g., via start/end times, machine assignments) and unscheduled ones pending dispatch. They balance progress (e.g., ratio, remaining workload), quality (e.g., makespan, waiting time), and status (e.g., utilization, queues, critical path), all computable in O(n*m) or less time using standard schedule data structures like Gantt charts or priority queues. In hyper-heuristics, such states enable adaptive heuristic selection—e.g., high queue lengths might favor tie-breaking rules. They inherently tie to the instance (e.g., total operations) but update with the solution. If your partial solution format (e.g., disjunctive graph or simulation-based) requires adjustments, like incorporating due dates for tardiness, we can refine; otherwise, these provide a robust, multi-dimensional snapshot.
------------------------------------------------------------------------------------

user
Try to implement the get_solution_problem_state function in python:
def get_solution_problem_state(instance_data: dict, solution: Solution) -> dict:

The input is instance_data:
- job_operation_sequence (numpy.ndarray): A list of jobs where each job is a list of operations in target sequence.
    - job_operation_time (numpy.ndarray): The time cost for each operation in target job.
    - job_num (int): The total number of jobs in the problem.
    - machine_num (int): The total number of machines in the problem, also as operation num.
The format of solution is already defined as:
class Solution:
    """The solution for the Job Shop Scheduling Problem (JSSP).
A list of lists where each sublist represents the sequence of jobs scheduled on a machine, identified by its index in the outer list.
Each job is represented by its integer identifier and is processed in the order specified within the sublist.
Each sublist in 'job_sequences' corresponds to a machine's job processing sequence, with machines sorted by their identifier (index in the outer list).
Each job within a sublist is sorted by its scheduled order of execution on that machine.
Job matrix records the target operation(machine) sequence in job."""
    def __init__(self, job_sequences: list[list[int]], job_operation_sequence: list[list[int]], job_operation_index: list[int]):
        self.job_sequences = job_sequences
        self.job_operation_sequence = job_operation_sequence
        self.job_operation_index = job_operation_index

The output is algo a dict, which contains the following problem states as keys: scheduled_operations_ratio,current_makespan,avg_machine_utilization,remaining_workload,max_machine_queue_length,critical_path_length,avg_operation_waiting_time.

Please note:
1. Never modify the instance_data and solution.
2. The name of function must be get_solution_problem_state.
3. No any omissions or placeholders, I'm just going to use the code.
4. Comments in the code are very important.
5. The solution is already defined, do not implement it again.

The response format is very important. For better communication, please respond to me in this format:
***python_code:
import library (if necessary)
def get_solution_problem_state(instance_data: dict, solution: Solution) -> dict:
    """Extract instance problem state from instance data.

    Args:
        instance_data (dict): The dictionary contains the instance data.
        solution (Solution): The target solution instance.
    Returns:
        dict: The dictionary contains the instance problem state with:
            - problem_state_name (type): description
            - problem_state_name (type): description
            ...
    """
    ...
***
Ensure there is no other content inside the ***, and analysis outside *** is welcome.
If you have no information to provide, simply respond with ***None***.
------------------------------------------------------------------------------------

assistant
***python_code:
import numpy as np

def get_solution_problem_state(instance_data: dict, solution: Solution) -> dict:
    """Extract solution problem state from instance data and solution.

    Args:
        instance_data (dict): The dictionary contains the instance data.
        solution (Solution): The target solution instance.

    Returns:
        dict: The dictionary contains the solution problem state with:
            - scheduled_operations_ratio (float): Ratio of scheduled operations to total operations.
            - current_makespan (float): Maximum completion time among scheduled operations.
            - avg_machine_utilization (float): Average utilization across machines based on busy time over makespan.
            - remaining_workload (float): Total processing time of all unscheduled operations.
            - max_machine_queue_length (int): Maximum number of eligible unscheduled operations waiting for any machine.
            - critical_path_length (float): Length (time) of the longest path to a scheduled operation.
            - avg_operation_waiting_time (float): Average waiting time of scheduled operations beyond their job release.
    """
    # Extract basic parameters from instance_data without modification
    job_num = instance_data['job_num']
    machine_num = instance_data['machine_num']
    processing_times = instance_data['job_operation_time']  # 2D np.array of shape (job_num, machine_num)
    
    # Extract solution data
    job_sequences = solution.job_sequences  # list[list[int]]: order of jobs per machine
    job_op_seq = solution.job_operation_sequence  # list[list[int]]: machine sequence per job
    job_op_index = solution.job_operation_index  # list[int]: number of scheduled operations per job
    
    # Calculate scheduled_operations_ratio
    total_scheduled = sum(job_op_index)
    total_operations = job_num * machine_num
    scheduled_operations_ratio = total_scheduled / total_operations if total_operations > 0 else 0.0
    
    # Calculate remaining_workload: sum of processing times for unscheduled operations
    remaining_workload = 0.0
    for j in range(job_num):
        remaining_workload += np.sum(processing_times[j, job_op_index[j]:])
    
    # Calculate max_machine_queue_length: count eligible next operations per machine
    queue_lengths = [0] * machine_num
    for j in range(job_num):
        next_i = job_op_index[j]
        if next_i < machine_num:
            next_m = job_op_seq[j][next_i]
            if 0 <= next_m < machine_num:  # Ensure valid machine index
                queue_lengths[next_m] += 1
    max_machine_queue_length = max(queue_lengths) if queue_lengths else 0
    
    # Build ordered operations per machine: list[list[tuple[int, int]]] for (j, i) in processing order
    op_order_per_machine = [[] for _ in range(machine_num)]
    for m in range(machine_num):
        for j in job_sequences[m]:
            if 0 <= j < job_num:  # Ensure valid job index
                found = False
                for i in range(job_op_index[j]):
                    if job_op_seq[j][i] == m:
                        op_order_per_machine[m].append((j, i))
                        found = True
                        break
                # Assume found; if not, the operation is not scheduled and skipped
    
    # Initialize start and end times for all potentially scheduled operations
    start_time = [[0.0] * machine_num for _ in range(job_num)]
    end_time = [[0.0] * machine_num for _ in range(job_num)]
    
    # Initial assignment: start at 0, end at processing time for scheduled ops
    for j in range(job_num):
        for i in range(job_op_index[j]):
            end_time[j][i] = processing_times[j][i]
            start_time[j][i] = 0.0  # Will be updated in iteration
    
    # Iterative computation of start/end times using constraint propagation (converges for DAG)
    changed = True
    iteration = 0
    max_iterations = job_num * machine_num  # Sufficient for convergence
    while changed and iteration < max_iterations:
        iteration += 1
        changed = False
        for m in range(machine_num):
            order_list = op_order_per_machine[m]
            for pos, (j, i) in enumerate(order_list):
                p = processing_times[j][i]
                # Predecessor from job chain
                pred_job = end_time[j][i - 1] if i > 0 else 0.0
                # Predecessor from machine sequence
                pred_machine = 0.0
                if pos > 0:
                    prev_j, prev_i = order_list[pos - 1]
                    pred_machine = end_time[prev_j][prev_i]
                # New start time
                new_start = max(pred_job, pred_machine)
                new_end = new_start + p
                # Check for update (with tolerance for floating-point)
                if abs(start_time[j][i] - new_start) > 1e-6 or abs(end_time[j][i] - new_end) > 1e-6:
                    start_time[j][i] = new_start
                    end_time[j][i] = new_end
                    changed = True
    
    # Calculate current_makespan: max end time over scheduled operations
    current_makespan = 0.0
    for j in range(job_num):
        for i in range(job_op_index[j]):
            current_makespan = max(current_makespan, end_time[j][i])
    
    # Set critical_path_length as the time length of the longest path (equivalent to makespan here)
    critical_path_length = current_makespan
    
    # Calculate avg_machine_utilization: average of (busy time / makespan) per machine
    utilizations = []
    for m in range(machine_num):
        busy = 0.0
        for (j, i) in op_order_per_machine[m]:
            busy += processing_times[j][i]
        util = busy / current_makespan if current_makespan > 0 else 0.0
        utilizations.append(util)
    avg_machine_utilization = np.mean(utilizations) if utilizations else 0.0
    
    # Calculate avg_operation_waiting_time: average (start - job release) over scheduled ops
    total_wait = 0.0
    num_scheduled = total_scheduled
    for j in range(job_num):
        for i in range(job_op_index[j]):
            release = end_time[j][i - 1] if i > 0 else 0.0
            wait = start_time[j][i] - release
            total_wait += wait
    avg_operation_waiting_time = total_wait / num_scheduled if num_scheduled > 0 else 0.0
    
    # Return the solution problem state as a dictionary
    return {
        'scheduled_operations_ratio': scheduled_operations_ratio,
        'current_makespan': current_makespan,
        'avg_machine_utilization': avg_machine_utilization,
        'remaining_workload': remaining_workload,
        'max_machine_queue_length': max_machine_queue_length,
        'critical_path_length': critical_path_length,
        'avg_operation_waiting_time': avg_operation_waiting_time
    }
***
This implementation simulates the partial schedule using constraint propagation on the disjunctive graph defined by job precedences and machine job orders, ensuring accurate computation of time-based features without modifying inputs. It assumes the Solution represents a consistent partial state where job_sequences[m] only includes jobs with their corresponding operation scheduled (i.e., within job_op_index[j]). The iterative update converges in few passes for typical JSSP sizes (e.g., <100 iterations for 20x20). Floating-point tolerance prevents unnecessary loops. Queue lengths capture eligible next operations (assuming job predecessors are completed). If the representation allows idle times or different dispatching semantics, or if job_operation_index indicates something else (e.g., pending index), minor adjustments may be needed; validation could be added for consistency (e.g., all listed jobs have the op scheduled). The code is self-contained, efficient (O(n m^2) worst-case but practical), and directly usable.
------------------------------------------------------------------------------------

user
Then, we need to filter some core problem state in solution problem state to record the changes of solution, please select some problem state in solution problem state.


In determining the optimal problem states to represent instance, we must adhere to the following criteria:
1. Must select from solution problem state, not instance problem state


The response format is very important. For better communication, please respond to me in this format:
***observation_problem_state:
problem_state_name;
problem_state_name;
....
***
Ensure there is no other content inside the ***, and analysis outside *** is welcome.
If you have no information to provide, simply respond with ***None***.
------------------------------------------------------------------------------------

assistant
***observation_problem_state:
scheduled_operations_ratio;
current_makespan;
remaining_workload;
avg_operation_waiting_time;
***
These selected states form a core subset focused on tracking solution evolution: progress (scheduled_operations_ratio), quality (current_makespan and avg_operation_waiting_time), and remaining effort (remaining_workload). They capture key dynamics during iterative solving (e.g., in hyper-heuristics or local search), omitting more static or computationally intensive ones like max_machine_queue_length or critical_path_length to prioritize succinct monitoring of changes without redundancy. avg_machine_utilization could be added if efficiency tracking is emphasized, but this set balances multi-dimensional observation with low overhead for logging or adaptation.
------------------------------------------------------------------------------------

user
Try to implement the get_observation_problem_state function in python:
def get_observation_problem_state(solution_problem_state: dict) -> dict:

The input is solution_problem_state.

The output is algo a dict, which contains the following problem states as keys: scheduled_operations_ratio,current_makespan,remaining_workload,avg_operation_waiting_time.

Please note:
1. Just take it from solution_problem_state without modify it.
2. The name of function must be get_observation_problem_state.
3. No any omissions or placeholders, I'm just going to use the code.
4. Comments in the code are very important.


The response format is very important. For better communication, please respond to me in this format:
***python_code:
import library (if necessary)

def get_observation_problem_state(solution_problem_state: dict) -> dict:
    """Extract core problem state as observation.

    Args:
        solution_problem_state (dict): The dictionary contains the solution problem state.

    Returns:
        dict: The dictionary contains the core problem state.
    """
    return {
        "xxx": problem_state_name["xxx"],
        "xxx": problem_state_name["xxx"],
    }
***
Ensure there is no other content inside the ***, and analysis outside *** is welcome.
If you have no information to provide, simply respond with ***None***.
------------------------------------------------------------------------------------

assistant
***python_code:
def get_observation_problem_state(solution_problem_state: dict) -> dict:
    """Extract core problem state as observation.

    Args:
        solution_problem_state (dict): The dictionary contains the solution problem state.

    Returns:
        dict: The dictionary contains the core problem state with:
            - scheduled_operations_ratio (float): Ratio of scheduled operations to total operations.
            - current_makespan (float): Maximum completion time among scheduled operations.
            - remaining_workload (float): Total processing time of all unscheduled operations.
            - avg_operation_waiting_time (float): Average waiting time of scheduled operations beyond their job release.
    """
    # Extract the selected keys from the input dictionary without any modifications
    # This creates a subset dict for observation, preserving original values
    return {
        'scheduled_operations_ratio': solution_problem_state['scheduled_operations_ratio'],
        'current_makespan': solution_problem_state['current_makespan'],
        'remaining_workload': solution_problem_state['remaining_workload'],
        'avg_operation_waiting_time': solution_problem_state['avg_operation_waiting_time']
    }
***
This function simply subsets the input dictionary to the specified core states, ensuring no data alteration and minimal computational overhead (O(1) time). It assumes all required keys exist in the input; in production, key existence checks could be added for robustness, but per instructions, it's direct extraction without extras. This facilitates efficient logging or monitoring of solution changes in hyper-heuristic frameworks.
------------------------------------------------------------------------------------

