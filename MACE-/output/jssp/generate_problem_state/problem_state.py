# This file is generated by generate_problem_state.py.

from src.problems.jssp.components import Solution


import numpy as np

def get_instance_problem_state(instance_data: dict) -> dict:
    """Extract instance problem state from instance data.

    Args:
        instance_data (dict): The dictionary contains the instance data.

    Returns:
        dict: The dictionary contains the instance problem state with:
            - num_jobs (int): The total number of jobs in the problem.
            - num_machines (int): The total number of machines in the problem.
            - avg_processing_time (float): The average processing time across all operations.
            - coeff_variation_processing_times (float): The coefficient of variation of processing times.
            - machine_load_variance (float): The variance of total processing times (loads) across machines.
            - max_processing_time (float): The maximum processing time among all operations.
    """
    # Extract basic parameters from instance_data without modification
    job_num = instance_data['job_num']
    machine_num = instance_data['machine_num']
    processing_times = instance_data['job_operation_time']  # Assumed to be a 2D numpy array of shape (job_num, machine_num)
    
    # Calculate number of jobs and machines directly
    num_jobs = job_num
    num_machines = machine_num
    
    # Calculate average processing time: total sum divided by total number of operations
    total_sum = np.sum(processing_times)
    total_operations = job_num * machine_num
    avg_processing_time = total_sum / total_operations if total_operations > 0 else 0.0
    
    # Calculate coefficient of variation: standard deviation divided by mean
    std_processing_times = np.std(processing_times)
    coeff_variation_processing_times = (std_processing_times / avg_processing_time) if avg_processing_time > 0 else 0.0
    
    # Calculate machine load variance: first compute sum of processing times per machine (column sums),
    # then compute variance across these machine loads
    machine_loads = np.sum(processing_times, axis=0)  # Shape: (machine_num,)
    machine_load_variance = np.var(machine_loads)
    
    # Calculate maximum processing time across all operations
    max_processing_time = np.max(processing_times)
    
    # Return the problem state as a dictionary
    return {
        'num_jobs': num_jobs,
        'num_machines': num_machines,
        'avg_processing_time': avg_processing_time,
        'coeff_variation_processing_times': coeff_variation_processing_times,
        'machine_load_variance': machine_load_variance,
        'max_processing_time': max_processing_time
    }

from src.problems.jssp.components import Solution
import numpy as np

def get_solution_problem_state(instance_data: dict, solution: Solution) -> dict:
    """Extract solution problem state from instance data and solution.

    Args:
        instance_data (dict): The dictionary contains the instance data.
        solution (Solution): The target solution instance.

    Returns:
        dict: The dictionary contains the solution problem state with:
            - scheduled_operations_ratio (float): Ratio of scheduled operations to total operations.
            - current_makespan (float): Maximum completion time among scheduled operations.
            - avg_machine_utilization (float): Average utilization across machines based on busy time over makespan.
            - remaining_workload (float): Total processing time of all unscheduled operations.
            - max_machine_queue_length (int): Maximum number of eligible unscheduled operations waiting for any machine.
            - critical_path_length (float): Length (time) of the longest path to a scheduled operation.
            - avg_operation_waiting_time (float): Average waiting time of scheduled operations beyond their job release.
    """
    # Extract basic parameters from instance_data without modification
    job_num = instance_data['job_num']
    machine_num = instance_data['machine_num']
    processing_times = instance_data['job_operation_time']  # 2D np.array of shape (job_num, machine_num)
    
    # Extract solution data
    job_sequences = solution.job_sequences  # list[list[int]]: order of jobs per machine
    job_op_seq = solution.job_operation_sequence  # list[list[int]]: machine sequence per job
    job_op_index = solution.job_operation_index  # list[int]: number of scheduled operations per job
    
    # Calculate scheduled_operations_ratio
    total_scheduled = sum(job_op_index)
    total_operations = job_num * machine_num
    scheduled_operations_ratio = total_scheduled / total_operations if total_operations > 0 else 0.0
    
    # Calculate remaining_workload: sum of processing times for unscheduled operations
    remaining_workload = 0.0
    for j in range(job_num):
        remaining_workload += np.sum(processing_times[j, job_op_index[j]:])
    
    # Calculate max_machine_queue_length: count eligible next operations per machine
    queue_lengths = [0] * machine_num
    for j in range(job_num):
        next_i = job_op_index[j]
        if next_i < machine_num:
            next_m = job_op_seq[j][next_i]
            if 0 <= next_m < machine_num:  # Ensure valid machine index
                queue_lengths[next_m] += 1
    max_machine_queue_length = max(queue_lengths) if queue_lengths else 0
    
    # Build ordered operations per machine: list[list[tuple[int, int]]] for (j, i) in processing order
    op_order_per_machine = [[] for _ in range(machine_num)]
    for m in range(machine_num):
        for j in job_sequences[m]:
            if 0 <= j < job_num:  # Ensure valid job index
                found = False
                for i in range(job_op_index[j]):
                    if job_op_seq[j][i] == m:
                        op_order_per_machine[m].append((j, i))
                        found = True
                        break
                # Assume found; if not, the operation is not scheduled and skipped
    
    # Initialize start and end times for all potentially scheduled operations
    start_time = [[0.0] * machine_num for _ in range(job_num)]
    end_time = [[0.0] * machine_num for _ in range(job_num)]
    
    # Initial assignment: start at 0, end at processing time for scheduled ops
    for j in range(job_num):
        for i in range(job_op_index[j]):
            end_time[j][i] = processing_times[j][i]
            start_time[j][i] = 0.0  # Will be updated in iteration
    
    # Iterative computation of start/end times using constraint propagation (converges for DAG)
    changed = True
    iteration = 0
    max_iterations = job_num * machine_num  # Sufficient for convergence
    while changed and iteration < max_iterations:
        iteration += 1
        changed = False
        for m in range(machine_num):
            order_list = op_order_per_machine[m]
            for pos, (j, i) in enumerate(order_list):
                p = processing_times[j][i]
                # Predecessor from job chain
                pred_job = end_time[j][i - 1] if i > 0 else 0.0
                # Predecessor from machine sequence
                pred_machine = 0.0
                if pos > 0:
                    prev_j, prev_i = order_list[pos - 1]
                    pred_machine = end_time[prev_j][prev_i]
                # New start time
                new_start = max(pred_job, pred_machine)
                new_end = new_start + p
                # Check for update (with tolerance for floating-point)
                if abs(start_time[j][i] - new_start) > 1e-6 or abs(end_time[j][i] - new_end) > 1e-6:
                    start_time[j][i] = new_start
                    end_time[j][i] = new_end
                    changed = True
    
    # Calculate current_makespan: max end time over scheduled operations
    current_makespan = 0.0
    for j in range(job_num):
        for i in range(job_op_index[j]):
            current_makespan = max(current_makespan, end_time[j][i])
    
    # Set critical_path_length as the time length of the longest path (equivalent to makespan here)
    critical_path_length = current_makespan
    
    # Calculate avg_machine_utilization: average of (busy time / makespan) per machine
    utilizations = []
    for m in range(machine_num):
        busy = 0.0
        for (j, i) in op_order_per_machine[m]:
            busy += processing_times[j][i]
        util = busy / current_makespan if current_makespan > 0 else 0.0
        utilizations.append(util)
    avg_machine_utilization = np.mean(utilizations) if utilizations else 0.0
    
    # Calculate avg_operation_waiting_time: average (start - job release) over scheduled ops
    total_wait = 0.0
    num_scheduled = total_scheduled
    for j in range(job_num):
        for i in range(job_op_index[j]):
            release = end_time[j][i - 1] if i > 0 else 0.0
            wait = start_time[j][i] - release
            total_wait += wait
    avg_operation_waiting_time = total_wait / num_scheduled if num_scheduled > 0 else 0.0
    
    # Return the solution problem state as a dictionary
    return {
        'scheduled_operations_ratio': scheduled_operations_ratio,
        'current_makespan': current_makespan,
        'avg_machine_utilization': avg_machine_utilization,
        'remaining_workload': remaining_workload,
        'max_machine_queue_length': max_machine_queue_length,
        'critical_path_length': critical_path_length,
        'avg_operation_waiting_time': avg_operation_waiting_time
    }

def get_observation_problem_state(solution_problem_state: dict) -> dict:
    """Extract core problem state as observation.

    Args:
        solution_problem_state (dict): The dictionary contains the solution problem state.

    Returns:
        dict: The dictionary contains the core problem state with:
            - scheduled_operations_ratio (float): Ratio of scheduled operations to total operations.
            - current_makespan (float): Maximum completion time among scheduled operations.
            - remaining_workload (float): Total processing time of all unscheduled operations.
            - avg_operation_waiting_time (float): Average waiting time of scheduled operations beyond their job release.
    """
    # Extract the selected keys from the input dictionary without any modifications
    # This creates a subset dict for observation, preserving original values
    return {
        'scheduled_operations_ratio': solution_problem_state['scheduled_operations_ratio'],
        'current_makespan': solution_problem_state['current_makespan'],
        'remaining_workload': solution_problem_state['remaining_workload'],
        'avg_operation_waiting_time': solution_problem_state['avg_operation_waiting_time']
    }