{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "690b67b3-5905-4846-9455-4de2b6e85cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import Dict, List, Tuple, Any, Set\n",
    "from openai import OpenAI\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import importlib\n",
    "from datetime import datetime\n",
    "from src.pipeline.hyper_heuristics.single import SingleHyperHeuristic\n",
    "from src.util.llm_client.get_llm_client import get_llm_client\n",
    "from src.util.util import search_file\n",
    "from src.run_hyper_heuristic.run_hyper_heuristic import run_hyper_heuristic, evaluate_all_heuristics\n",
    "from src.run_hyper_heuristic.helper_function import select_complementary_pair, load_heuristic_code, extract_code_from_response, save_generated_heuristic, select_parent_for_local_search\n",
    "from src.run_hyper_heuristic.prompt_cs import CSPromptFormatter, generate_complementary_heuristic, call_deepseek_reasoner\n",
    "from src.run_hyper_heuristic.prompt_ls import LSPromptFormatter, generate_complementary_ls_heuristic\n",
    "from src.run_hyper_heuristic.prompt_ie import IEPromptFormatter, generate_complementary_ie_heuristic\n",
    "from src.run_hyper_heuristic.smoke_test import SmokeTestRunner,standalone_smoke_test\n",
    "from src.run_hyper_heuristic.complete_cs_workflow import complete_cs_workflow\n",
    "from src.run_hyper_heuristic.local_search_workflow import local_search_workflow\n",
    "from src.run_hyper_heuristic.improve_efficiency import improve_efficiency\n",
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e805d794-e8c4-4861-98d8-6e024e70f5ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ğŸ“‹ æ­¥éª¤ 1: è¯„ä¼°åˆå§‹å¯å‘å¼\n",
      "================================================================================\n",
      "æ‰¾åˆ° 4 ä¸ªå¯å‘å¼ç®—æ³•:\n",
      "\n",
      "============================================================\n",
      "test_dataè¯„ä¼°å®Œæˆï¼ç»“æœæ±‡æ€»:\n",
      "============================================================\n",
      "{'least_remaining_workload_lwr_d24d': [3193, 3887, 3101, 3780, 4391], 'longest_processing_time_lpt_e2c3': [2279, 3068, 2788, 3011, 3352], 'random_selection_b73a': [1497, 1601, 1721, 1869, 1699], 'shortest_processing_time_spt_4363': [2182, 3164, 2500, 2721, 3351]}\n",
      "\n",
      "================================================================================\n",
      "ğŸ“‹ æ­¥éª¤ 2: è¿è¡Œ EoH-S\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "ğŸš€ EoH-S ç®—æ³•å¼€å§‹\n",
      "================================================================================\n",
      "é…ç½®: ç§ç¾¤å¤§å°=5, æœ€å¤§è¯„ä¼°æ¬¡æ•°=100\n",
      "\n",
      "âœ“ åˆå§‹åŒ–ç§ç¾¤: 4 ä¸ªå¯å‘å¼\n",
      "\n",
      "================================================================================\n",
      "ğŸ“ˆ ç¬¬ 1 ä»£è¿›åŒ– (å·²è¯„ä¼°: 0/100)\n",
      "================================================================================\n",
      "\n",
      "ğŸ”„ å¼€å§‹Memetic Searchï¼Œç›®æ ‡ç”Ÿæˆ 5 ä¸ªæ–°å¯å‘å¼\n",
      "\n",
      "  ğŸ”§ å°è¯• LS #1/5 (å°è¯• 1/25)\n",
      "\n",
      "================================================================================\n",
      "âœ… lså·¥ä½œæµå¼€å§‹!\n",
      "    âŒ LS å¤±è´¥: [Errno 2] No such file or directory: '\\\\src\\\\problems\\\\jssp\\\\task_description.txt'\n",
      "\n",
      "  ğŸ”§ å°è¯• LS #1/5 (å°è¯• 2/25)\n",
      "\n",
      "================================================================================\n",
      "âœ… lså·¥ä½œæµå¼€å§‹!\n",
      "    âŒ LS å¤±è´¥: [Errno 2] No such file or directory: '\\\\src\\\\problems\\\\jssp\\\\task_description.txt'\n",
      "\n",
      "  ğŸ”§ å°è¯• LS #1/5 (å°è¯• 3/25)\n",
      "\n",
      "================================================================================\n",
      "âœ… lså·¥ä½œæµå¼€å§‹!\n",
      "    âŒ LS å¤±è´¥: [Errno 2] No such file or directory: '\\\\src\\\\problems\\\\jssp\\\\task_description.txt'\n",
      "\n",
      "  ğŸ” å°è¯• CS #1/5 (å°è¯• 4/25)\n",
      "âœ“ é€‰æ‹©çš„äº’è¡¥å¯¹: longest_processing_time_lpt_e2c3 å’Œ random_selection_b73a\n",
      "âœ“ ä»£ç å·²ä¿å­˜åˆ°: \\src\\problems\\jssp\\heuristics\\basic_heuristics\\shortest_processing_time_spt_k9m2.py\n",
      "\n",
      "================================================================================\n",
      "âœ… CSå·¥ä½œæµå®Œæˆ!\n",
      "================================================================================\n",
      "ğŸ“ ç”Ÿæˆçš„å¯å‘å¼ä»£ç : \\src\\problems\\jssp\\heuristics\\basic_heuristics\\shortest_processing_time_spt_k9m2.py\n",
      "ğŸ“„ å®Œæ•´å“åº”è®°å½•: \\src\\problems\\jssp\\heuristics\\basic_heuristics\\shortest_processing_time_spt_k9m2_full_response.txt\n",
      "ğŸ”¬ åŸºäºäº’è¡¥å¯¹: longest_processing_time_lpt_e2c3 + random_selection_b73a\n",
      "================================================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "ğŸ§ª è¿è¡ŒSmoke Test: shortest_processing_time_spt_k9m2\n",
      "============================================================\n",
      "âŒ Smoke Test å¤±è´¥:\n",
      "AssertionError: \n",
      "\n",
      "å †æ ˆè¿½è¸ª:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\gongh\\MACE\\MACE-main\\src\\run_hyper_heuristic\\smoke_test.py\", line 50, in run_smoke_test\n",
      "    validation_result = run_hyper_heuristic(\n",
      "                        ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\gongh\\MACE\\MACE-main\\src\\run_hyper_heuristic\\run_hyper_heuristic.py\", line 42, in run_hyper_heuristic\n",
      "    hyper_heuristic = SingleHyperHeuristic(heuristic=heuristic_name, problem=problem)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\gongh\\MACE\\MACE-main\\src\\pipeline\\hyper_heuristics\\single.py\", line 16, in __init__\n",
      "    self.heuristic = load_function(heuristic, problem=problem)  # åŠ è½½å¯å‘å¼å‡½æ•°å¹¶å­˜å‚¨åœ¨å®ä¾‹å˜é‡ä¸­\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\gongh\\MACE\\MACE-main\\src\\util\\util.py\", line 90, in load_function\n",
      "    assert file_path is not None\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError\n",
      "\n",
      "\n",
      "============================================================\n",
      "ğŸ”§ å°è¯•ä¿®å¤ (ç¬¬ 1/3 æ¬¡)\n",
      "============================================================\n",
      "æ­£åœ¨è°ƒç”¨DeepSeekä¿®å¤ä»£ç ...\n",
      "âœ“ LLMå·²ç”Ÿæˆä¿®å¤ä»£ç \n",
      "âœ“ ä»£ç å·²ä¿å­˜åˆ°: \\src\\problems\\jssp\\heuristics\\basic_heuristics\\shortest_processing_time_spt_k9m2.py\n",
      "\n",
      "============================================================\n",
      "ğŸ§ª è¿è¡ŒSmoke Test: shortest_processing_time_spt_k9m2\n",
      "============================================================\n",
      "âŒ Smoke Test å¤±è´¥:\n",
      "AssertionError: \n",
      "\n",
      "å †æ ˆè¿½è¸ª:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\gongh\\MACE\\MACE-main\\src\\run_hyper_heuristic\\smoke_test.py\", line 50, in run_smoke_test\n",
      "    validation_result = run_hyper_heuristic(\n",
      "                        ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\gongh\\MACE\\MACE-main\\src\\run_hyper_heuristic\\run_hyper_heuristic.py\", line 42, in run_hyper_heuristic\n",
      "    hyper_heuristic = SingleHyperHeuristic(heuristic=heuristic_name, problem=problem)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\gongh\\MACE\\MACE-main\\src\\pipeline\\hyper_heuristics\\single.py\", line 16, in __init__\n",
      "    self.heuristic = load_function(heuristic, problem=problem)  # åŠ è½½å¯å‘å¼å‡½æ•°å¹¶å­˜å‚¨åœ¨å®ä¾‹å˜é‡ä¸­\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\gongh\\MACE\\MACE-main\\src\\util\\util.py\", line 90, in load_function\n",
      "    assert file_path is not None\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError\n",
      "\n",
      "\n",
      "============================================================\n",
      "ğŸ”§ å°è¯•ä¿®å¤ (ç¬¬ 2/3 æ¬¡)\n",
      "============================================================\n",
      "æ­£åœ¨è°ƒç”¨DeepSeekä¿®å¤ä»£ç ...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 427\u001b[0m\n\u001b[0;32m    424\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m     å¹³å‡æ€§èƒ½: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mh[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavg_performance\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    426\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 427\u001b[0m     main()\n",
      "Cell \u001b[1;32mIn[4], line 412\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;66;03m# è¿è¡Œ EoH-S\u001b[39;00m\n\u001b[0;32m    400\u001b[0m eohs \u001b[38;5;241m=\u001b[39m EoHS(\n\u001b[0;32m    401\u001b[0m     problem\u001b[38;5;241m=\u001b[39mproblem,\n\u001b[0;32m    402\u001b[0m     api_key\u001b[38;5;241m=\u001b[39mapi_key,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    409\u001b[0m     time_limit\u001b[38;5;241m=\u001b[39mtime_limit\n\u001b[0;32m    410\u001b[0m )\n\u001b[1;32m--> 412\u001b[0m final_population \u001b[38;5;241m=\u001b[39m eohs\u001b[38;5;241m.\u001b[39mrun(results_dict,time_limit)\n\u001b[0;32m    414\u001b[0m \u001b[38;5;66;03m# è¾“å‡ºæœ€ç»ˆç»“æœ\u001b[39;00m\n\u001b[0;32m    415\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m80\u001b[39m)\n",
      "Cell \u001b[1;32mIn[4], line 320\u001b[0m, in \u001b[0;36mEoHS.run\u001b[1;34m(self, initial_results_dict, time_limit)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m80\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    319\u001b[0m \u001b[38;5;66;03m# (a) Memetic Search: ç”Ÿæˆ n ä¸ªæ–°å¯å‘å¼\u001b[39;00m\n\u001b[1;32m--> 320\u001b[0m new_heuristics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmemetic_search(population, initial_results_dict,time_limit)\n\u001b[0;32m    322\u001b[0m \u001b[38;5;66;03m# å¦‚æœæ²¡æœ‰ç”Ÿæˆä»»ä½•æ–°å¯å‘å¼ï¼Œæå‰ç»ˆæ­¢\u001b[39;00m\n\u001b[0;32m    323\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m new_heuristics:\n",
      "Cell \u001b[1;32mIn[4], line 78\u001b[0m, in \u001b[0;36mEoHS.memetic_search\u001b[1;34m(self, population, results_dict, time_limit)\u001b[0m\n\u001b[0;32m     67\u001b[0m file_path, code \u001b[38;5;241m=\u001b[39m complete_cs_workflow(\n\u001b[0;32m     68\u001b[0m     results_dict\u001b[38;5;241m=\u001b[39mresults_dict,\n\u001b[0;32m     69\u001b[0m     api_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     74\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\n\u001b[0;32m     75\u001b[0m )\n\u001b[0;32m     77\u001b[0m \u001b[38;5;66;03m# çƒŸé›¾æµ‹è¯•\u001b[39;00m\n\u001b[1;32m---> 78\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m standalone_smoke_test(file_path, api_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key):\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;66;03m# è¯„ä¼°æ–°å¯å‘å¼\u001b[39;00m\n\u001b[0;32m     80\u001b[0m     perf_vector, avg_perf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluate_heuristic(file_path,time_limit)\n\u001b[0;32m     81\u001b[0m     feability \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\MACE\\MACE-main\\src\\run_hyper_heuristic\\smoke_test.py:271\u001b[0m, in \u001b[0;36mstandalone_smoke_test\u001b[1;34m(heuristic_file, api_key)\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstandalone_smoke_test\u001b[39m(heuristic_file: \u001b[38;5;28mstr\u001b[39m, api_key: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[0;32m    266\u001b[0m     tester \u001b[38;5;241m=\u001b[39m SmokeTestRunner(\n\u001b[0;32m    267\u001b[0m         max_fix_attempts\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[0;32m    268\u001b[0m         api_key\u001b[38;5;241m=\u001b[39mapi_key\n\u001b[0;32m    269\u001b[0m     )\n\u001b[1;32m--> 271\u001b[0m     success, _ \u001b[38;5;241m=\u001b[39m tester\u001b[38;5;241m.\u001b[39mtest_and_fix_cycle(heuristic_file)\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m success\n",
      "File \u001b[1;32m~\\MACE\\MACE-main\\src\\run_hyper_heuristic\\smoke_test.py:221\u001b[0m, in \u001b[0;36mSmokeTestRunner.test_and_fix_cycle\u001b[1;34m(self, heuristic_file, save_fixed)\u001b[0m\n\u001b[0;32m    218\u001b[0m     current_code \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m    220\u001b[0m \u001b[38;5;66;03m# è®©LLMä¿®å¤\u001b[39;00m\n\u001b[1;32m--> 221\u001b[0m fixed_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfix_code_with_llm(current_code, error_msg, attempt)\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fixed_code:\n\u001b[0;32m    224\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mâŒ ä¿®å¤å¤±è´¥,æ”¾å¼ƒ\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\MACE\\MACE-main\\src\\run_hyper_heuristic\\smoke_test.py:165\u001b[0m, in \u001b[0;36mSmokeTestRunner.fix_code_with_llm\u001b[1;34m(self, original_code, error_message, attempt)\u001b[0m\n\u001b[0;32m    159\u001b[0m client \u001b[38;5;241m=\u001b[39m OpenAI(\n\u001b[0;32m    160\u001b[0m     api_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key,\n\u001b[0;32m    161\u001b[0m     base_url\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://openrouter.ai/api/v1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    162\u001b[0m )\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mæ­£åœ¨è°ƒç”¨DeepSeekä¿®å¤ä»£ç ...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 165\u001b[0m response \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[0;32m    166\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeepseek/deepseek-chat-v3.1\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;66;03m# ä½¿ç”¨chatæ¨¡å‹æ›´å¿«\u001b[39;00m\n\u001b[0;32m    167\u001b[0m     messages\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m    168\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are an expert Python debugger.\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    169\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: fix_prompt}\n\u001b[0;32m    170\u001b[0m     ],\n\u001b[0;32m    171\u001b[0m     temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m  \u001b[38;5;66;03m# é™ä½æ¸©åº¦ä»¥è·å¾—æ›´ç¡®å®šçš„ä¿®å¤\u001b[39;00m\n\u001b[0;32m    172\u001b[0m )\n\u001b[0;32m    174\u001b[0m llm_response \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n\u001b[0;32m    176\u001b[0m \u001b[38;5;66;03m# æå–ä¿®å¤åçš„ä»£ç \u001b[39;00m\n",
      "File \u001b[1;32mD:\\AppGallery\\Anaconda\\Lib\\site-packages\\openai\\_utils\\_utils.py:286\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    284\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 286\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\AppGallery\\Anaconda\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py:1192\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, prompt_cache_retention, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m   1145\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m   1147\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1189\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m not_given,\n\u001b[0;32m   1190\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m   1191\u001b[0m     validate_response_format(response_format)\n\u001b[1;32m-> 1192\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post(\n\u001b[0;32m   1193\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/chat/completions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1194\u001b[0m         body\u001b[38;5;241m=\u001b[39mmaybe_transform(\n\u001b[0;32m   1195\u001b[0m             {\n\u001b[0;32m   1196\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: messages,\n\u001b[0;32m   1197\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: model,\n\u001b[0;32m   1198\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio\u001b[39m\u001b[38;5;124m\"\u001b[39m: audio,\n\u001b[0;32m   1199\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrequency_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: frequency_penalty,\n\u001b[0;32m   1200\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction_call\u001b[39m\u001b[38;5;124m\"\u001b[39m: function_call,\n\u001b[0;32m   1201\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunctions\u001b[39m\u001b[38;5;124m\"\u001b[39m: functions,\n\u001b[0;32m   1202\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogit_bias\u001b[39m\u001b[38;5;124m\"\u001b[39m: logit_bias,\n\u001b[0;32m   1203\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: logprobs,\n\u001b[0;32m   1204\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_completion_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_completion_tokens,\n\u001b[0;32m   1205\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_tokens,\n\u001b[0;32m   1206\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[0;32m   1207\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodalities\u001b[39m\u001b[38;5;124m\"\u001b[39m: modalities,\n\u001b[0;32m   1208\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m: n,\n\u001b[0;32m   1209\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparallel_tool_calls\u001b[39m\u001b[38;5;124m\"\u001b[39m: parallel_tool_calls,\n\u001b[0;32m   1210\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m\"\u001b[39m: prediction,\n\u001b[0;32m   1211\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpresence_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: presence_penalty,\n\u001b[0;32m   1212\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt_cache_key\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt_cache_key,\n\u001b[0;32m   1213\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt_cache_retention\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt_cache_retention,\n\u001b[0;32m   1214\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreasoning_effort\u001b[39m\u001b[38;5;124m\"\u001b[39m: reasoning_effort,\n\u001b[0;32m   1215\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_format\u001b[39m\u001b[38;5;124m\"\u001b[39m: response_format,\n\u001b[0;32m   1216\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msafety_identifier\u001b[39m\u001b[38;5;124m\"\u001b[39m: safety_identifier,\n\u001b[0;32m   1217\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m\"\u001b[39m: seed,\n\u001b[0;32m   1218\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mservice_tier\u001b[39m\u001b[38;5;124m\"\u001b[39m: service_tier,\n\u001b[0;32m   1219\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop\u001b[39m\u001b[38;5;124m\"\u001b[39m: stop,\n\u001b[0;32m   1220\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstore\u001b[39m\u001b[38;5;124m\"\u001b[39m: store,\n\u001b[0;32m   1221\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream,\n\u001b[0;32m   1222\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream_options\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream_options,\n\u001b[0;32m   1223\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: temperature,\n\u001b[0;32m   1224\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_choice\u001b[39m\u001b[38;5;124m\"\u001b[39m: tool_choice,\n\u001b[0;32m   1225\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtools\u001b[39m\u001b[38;5;124m\"\u001b[39m: tools,\n\u001b[0;32m   1226\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_logprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_logprobs,\n\u001b[0;32m   1227\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_p\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_p,\n\u001b[0;32m   1228\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m: user,\n\u001b[0;32m   1229\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mverbosity\u001b[39m\u001b[38;5;124m\"\u001b[39m: verbosity,\n\u001b[0;32m   1230\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweb_search_options\u001b[39m\u001b[38;5;124m\"\u001b[39m: web_search_options,\n\u001b[0;32m   1231\u001b[0m             },\n\u001b[0;32m   1232\u001b[0m             completion_create_params\u001b[38;5;241m.\u001b[39mCompletionCreateParamsStreaming\n\u001b[0;32m   1233\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m stream\n\u001b[0;32m   1234\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m completion_create_params\u001b[38;5;241m.\u001b[39mCompletionCreateParamsNonStreaming,\n\u001b[0;32m   1235\u001b[0m         ),\n\u001b[0;32m   1236\u001b[0m         options\u001b[38;5;241m=\u001b[39mmake_request_options(\n\u001b[0;32m   1237\u001b[0m             extra_headers\u001b[38;5;241m=\u001b[39mextra_headers, extra_query\u001b[38;5;241m=\u001b[39mextra_query, extra_body\u001b[38;5;241m=\u001b[39mextra_body, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[0;32m   1238\u001b[0m         ),\n\u001b[0;32m   1239\u001b[0m         cast_to\u001b[38;5;241m=\u001b[39mChatCompletion,\n\u001b[0;32m   1240\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1241\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mStream[ChatCompletionChunk],\n\u001b[0;32m   1242\u001b[0m     )\n",
      "File \u001b[1;32mD:\\AppGallery\\Anaconda\\Lib\\site-packages\\openai\\_base_client.py:1259\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1245\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1246\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1247\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1254\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1255\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1256\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1257\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1258\u001b[0m     )\n\u001b[1;32m-> 1259\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(cast_to, opts, stream\u001b[38;5;241m=\u001b[39mstream, stream_cls\u001b[38;5;241m=\u001b[39mstream_cls))\n",
      "File \u001b[1;32mD:\\AppGallery\\Anaconda\\Lib\\site-packages\\openai\\_base_client.py:982\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[0;32m    980\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    981\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 982\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39msend(\n\u001b[0;32m    983\u001b[0m         request,\n\u001b[0;32m    984\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_stream_response_body(request\u001b[38;5;241m=\u001b[39mrequest),\n\u001b[0;32m    985\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    986\u001b[0m     )\n\u001b[0;32m    987\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    988\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered httpx.TimeoutException\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mD:\\AppGallery\\Anaconda\\Lib\\site-packages\\httpx\\_client.py:914\u001b[0m, in \u001b[0;36mClient.send\u001b[1;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[0;32m    910\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_timeout(request)\n\u001b[0;32m    912\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[1;32m--> 914\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_handling_auth(\n\u001b[0;32m    915\u001b[0m     request,\n\u001b[0;32m    916\u001b[0m     auth\u001b[38;5;241m=\u001b[39mauth,\n\u001b[0;32m    917\u001b[0m     follow_redirects\u001b[38;5;241m=\u001b[39mfollow_redirects,\n\u001b[0;32m    918\u001b[0m     history\u001b[38;5;241m=\u001b[39m[],\n\u001b[0;32m    919\u001b[0m )\n\u001b[0;32m    920\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    921\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[1;32mD:\\AppGallery\\Anaconda\\Lib\\site-packages\\httpx\\_client.py:942\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[1;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[0;32m    939\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[0;32m    941\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 942\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_handling_redirects(\n\u001b[0;32m    943\u001b[0m         request,\n\u001b[0;32m    944\u001b[0m         follow_redirects\u001b[38;5;241m=\u001b[39mfollow_redirects,\n\u001b[0;32m    945\u001b[0m         history\u001b[38;5;241m=\u001b[39mhistory,\n\u001b[0;32m    946\u001b[0m     )\n\u001b[0;32m    947\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    948\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mD:\\AppGallery\\Anaconda\\Lib\\site-packages\\httpx\\_client.py:979\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[1;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[0;32m    976\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    977\u001b[0m     hook(request)\n\u001b[1;32m--> 979\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_single_request(request)\n\u001b[0;32m    980\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    981\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[1;32mD:\\AppGallery\\Anaconda\\Lib\\site-packages\\httpx\\_client.py:1014\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m   1009\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1010\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1011\u001b[0m     )\n\u001b[0;32m   1013\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[1;32m-> 1014\u001b[0m     response \u001b[38;5;241m=\u001b[39m transport\u001b[38;5;241m.\u001b[39mhandle_request(request)\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[0;32m   1018\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[1;32mD:\\AppGallery\\Anaconda\\Lib\\site-packages\\httpx\\_transports\\default.py:250\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    237\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[0;32m    238\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m    239\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    247\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[0;32m    248\u001b[0m )\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[1;32m--> 250\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool\u001b[38;5;241m.\u001b[39mhandle_request(req)\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m    254\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[0;32m    255\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[0;32m    256\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m    257\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[0;32m    258\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[0;32m    259\u001b[0m )\n",
      "File \u001b[1;32mD:\\AppGallery\\Anaconda\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:256\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    253\u001b[0m         closing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_requests_to_connections()\n\u001b[0;32m    255\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[1;32m--> 256\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[0;32m    259\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n",
      "File \u001b[1;32mD:\\AppGallery\\Anaconda\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:236\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    232\u001b[0m connection \u001b[38;5;241m=\u001b[39m pool_request\u001b[38;5;241m.\u001b[39mwait_for_connection(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    234\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[1;32m--> 236\u001b[0m     response \u001b[38;5;241m=\u001b[39m connection\u001b[38;5;241m.\u001b[39mhandle_request(\n\u001b[0;32m    237\u001b[0m         pool_request\u001b[38;5;241m.\u001b[39mrequest\n\u001b[0;32m    238\u001b[0m     )\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[0;32m    242\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    243\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[0;32m    244\u001b[0m     pool_request\u001b[38;5;241m.\u001b[39mclear_connection()\n",
      "File \u001b[1;32mD:\\AppGallery\\Anaconda\\Lib\\site-packages\\httpcore\\_sync\\connection.py:103\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[1;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39mhandle_request(request)\n",
      "File \u001b[1;32mD:\\AppGallery\\Anaconda\\Lib\\site-packages\\httpcore\\_sync\\http11.py:136\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[0;32m    135\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[1;32m--> 136\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[1;32mD:\\AppGallery\\Anaconda\\Lib\\site-packages\\httpcore\\_sync\\http11.py:106\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[0;32m     99\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[0;32m    100\u001b[0m     (\n\u001b[0;32m    101\u001b[0m         http_version,\n\u001b[0;32m    102\u001b[0m         status,\n\u001b[0;32m    103\u001b[0m         reason_phrase,\n\u001b[0;32m    104\u001b[0m         headers,\n\u001b[0;32m    105\u001b[0m         trailing_data,\n\u001b[1;32m--> 106\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_receive_response_headers(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    107\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    108\u001b[0m         http_version,\n\u001b[0;32m    109\u001b[0m         status,\n\u001b[0;32m    110\u001b[0m         reason_phrase,\n\u001b[0;32m    111\u001b[0m         headers,\n\u001b[0;32m    112\u001b[0m     )\n\u001b[0;32m    114\u001b[0m network_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\n",
      "File \u001b[1;32mD:\\AppGallery\\Anaconda\\Lib\\site-packages\\httpcore\\_sync\\http11.py:177\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    174\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 177\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_receive_event(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[0;32m    179\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mD:\\AppGallery\\Anaconda\\Lib\\site-packages\\httpcore\\_sync\\http11.py:217\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    214\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[1;32m--> 217\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\u001b[38;5;241m.\u001b[39mread(\n\u001b[0;32m    218\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mREAD_NUM_BYTES, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[0;32m    219\u001b[0m     )\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    223\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[1;32mD:\\AppGallery\\Anaconda\\Lib\\site-packages\\httpcore\\_backends\\sync.py:128\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[1;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[0;32m    127\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[1;32m--> 128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39mrecv(max_bytes)\n",
      "File \u001b[1;32mD:\\AppGallery\\Anaconda\\Lib\\ssl.py:1296\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[1;34m(self, buflen, flags)\u001b[0m\n\u001b[0;32m   1292\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1293\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1294\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1295\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1296\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(buflen)\n\u001b[0;32m   1297\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[1;32mD:\\AppGallery\\Anaconda\\Lib\\ssl.py:1169\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1167\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[0;32m   1168\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1169\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n\u001b[0;32m   1170\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[0;32m   1171\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class EoHS:\n",
    "    \"\"\"Evolution of Heuristic Set\"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 problem: str,\n",
    "                 api_key: str,\n",
    "                 heuristic_dir: str,\n",
    "                 task_description_file: str,\n",
    "                 output_dir: str,\n",
    "                 model: str,\n",
    "                 population_size: int,\n",
    "                 max_evaluations: int,\n",
    "                 time_limit: int):\n",
    "        \n",
    "        self.problem = problem\n",
    "        self.api_key = api_key\n",
    "        self.heuristic_dir = heuristic_dir\n",
    "        self.task_description_file = task_description_file\n",
    "        self.output_dir = output_dir\n",
    "        self.n = population_size\n",
    "        self.Nmax = max_evaluations\n",
    "        self.model = model\n",
    "        self.evaluations = 0\n",
    "        self.llm_config_file = os.path.join(\"output\", \"llm_config\", \"azure_gpt_4o.json\")  \n",
    "        self.iterations_scale_factor = 1.0 \n",
    "        self.result_dir = \"result\"\n",
    "        self.time_limit = time_limit\n",
    "        \n",
    "        # ç”¨äºè·Ÿè¸ªå·²é€‰æ‹©çš„äº’è¡¥å¯¹\n",
    "        self.selected_pairs: Set[Tuple[str, str]] = set()\n",
    "       \n",
    "        \n",
    "    def initialize_population(self, results_dict: Dict) -> List[Dict]:\n",
    "        \"\"\"åˆå§‹åŒ–ç§ç¾¤ P0\"\"\"\n",
    "        population = []\n",
    "        for heuristic_name, heuristic_scores in results_dict.items():\n",
    "            heuristic_info = {\n",
    "                'name': heuristic_name,\n",
    "                'performance_vector': heuristic_scores,\n",
    "                'avg_performance': np.mean(heuristic_scores)\n",
    "            }\n",
    "            population.append(heuristic_info)\n",
    "        return population\n",
    "    \n",
    "    def memetic_search(self, population: List[Dict], results_dict: Dict, time_limit) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        äº’è¡¥æ„ŸçŸ¥çš„Memeticæœç´¢\n",
    "        ç›®æ ‡ï¼šç”Ÿæˆ n ä¸ªæ–°å¯å‘å¼\n",
    "        \"\"\"\n",
    "        new_heuristics = []\n",
    "        attempts = 0\n",
    "        max_attempts = self.n * 5  # å…è®¸ä¸€äº›å¤±è´¥å°è¯•\n",
    "        \n",
    "        print(f\"\\nğŸ”„ å¼€å§‹Memetic Searchï¼Œç›®æ ‡ç”Ÿæˆ {self.n} ä¸ªæ–°å¯å‘å¼\")\n",
    "        \n",
    "        while len(new_heuristics) < self.n and attempts < max_attempts:\n",
    "            attempts += 1\n",
    "            \n",
    "            # 50%æ¦‚ç‡ä½¿ç”¨CSï¼Œ50%ä½¿ç”¨LS\n",
    "            use_cs = random.random() < 0.5\n",
    "            \n",
    "            if use_cs:\n",
    "                # Complementary-aware Search\n",
    "                try:\n",
    "                    print(f\"\\n  ğŸ” å°è¯• CS #{len(new_heuristics)+1}/{self.n} (å°è¯• {attempts}/{max_attempts})\")\n",
    "                    \n",
    "                    file_path, code = complete_cs_workflow(\n",
    "                        results_dict=results_dict,\n",
    "                        api_key=self.api_key,\n",
    "                        problem=self.problem,\n",
    "                        heuristic_dir=self.heuristic_dir,\n",
    "                        task_description_file=self.task_description_file,\n",
    "                        output_dir=self.output_dir,\n",
    "                        model=self.model\n",
    "                    )\n",
    "                    \n",
    "                    # çƒŸé›¾æµ‹è¯•\n",
    "                    if standalone_smoke_test(file_path, api_key=self.api_key):\n",
    "                        # è¯„ä¼°æ–°å¯å‘å¼\n",
    "                        perf_vector, avg_perf = self.evaluate_heuristic(file_path,time_limit)\n",
    "                        feability = True\n",
    "                        penalty_value = 1e10-1\n",
    "                        for h_each_result in perf_vector:\n",
    "                            if h_each_result > penalty_value:\n",
    "                                feability = False \n",
    "                        if feability:\n",
    "                            print(f\" åŠ å…¥è¯¥æ–°ç®—æ³•: {file_path}\")\n",
    "                            new_heuristics.append({\n",
    "                                'name': file_path,\n",
    "                                'performance_vector': perf_vector,\n",
    "                                'avg_performance': avg_perf\n",
    "                            })\n",
    "                            print(f\"    âœ… CS æˆåŠŸ: {file_path} (avg: {avg_perf:.4f})\")\n",
    "                            self.evaluations += 1\n",
    "                        else:\n",
    "                            print('éœ€è¦è®¡ç®—æ—¶é—´æ•ˆç‡æå‡')\n",
    "                            file_path, code = improve_efficiency(\n",
    "                                                file_path=file_path,\n",
    "                                                api_key=self.api_key,\n",
    "                                                problem=self.problem,\n",
    "                                                heuristic_dir=self.heuristic_dir,\n",
    "                                                task_description_file=self.task_description_file,\n",
    "                                                output_dir=self.output_dir,\n",
    "                                                model=self.model\n",
    "                                            )\n",
    "                            # çƒŸé›¾æµ‹è¯•\n",
    "                            if standalone_smoke_test(file_path, api_key=self.api_key):\n",
    "                                # è¯„ä¼°æ–°å¯å‘å¼\n",
    "                                perf_vector, avg_perf = self.evaluate_heuristic(file_path,time_limit)\n",
    "                                feability = True\n",
    "                                penalty_value = 1e10-1\n",
    "                                for h_each_result in perf_vector:\n",
    "                                    if h_each_result > penalty_value:\n",
    "                                        feability = False \n",
    "                                if feability:\n",
    "                                    print(f\" åŠ å…¥è¯¥æ–°ç®—æ³•: {file_path}\")\n",
    "                                    new_heuristics.append({\n",
    "                                        'name': file_path,\n",
    "                                        'performance_vector': perf_vector,\n",
    "                                        'avg_performance': avg_perf\n",
    "                                    })\n",
    "                                    print(f\"    âœ… CS æˆåŠŸ: {file_path} (avg: {avg_perf:.4f})\")\n",
    "                                    self.evaluations += 1\n",
    "                                else:\n",
    "                                    print('æå‡è®¡ç®—æ—¶é—´æ•ˆç‡å¤±è´¥ï¼Œæ”¾å¼ƒè¯¥ç®—æ³•')\n",
    "\n",
    "                            else:\n",
    "                                print(f\"    âŒ CS çƒŸé›¾æµ‹è¯•å¤±è´¥\")\n",
    "                    else:\n",
    "                        print(f\"    âŒ CS çƒŸé›¾æµ‹è¯•å¤±è´¥\")\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    print(f\"    âŒ CS å¤±è´¥: {e}\")\n",
    "                    \n",
    "            else:\n",
    "                # Local Search\n",
    "                try:\n",
    "                    print(f\"\\n  ğŸ”§ å°è¯• LS #{len(new_heuristics)+1}/{self.n} (å°è¯• {attempts}/{max_attempts})\")\n",
    "                    \n",
    "                    file_path, code = local_search_workflow(\n",
    "                        results_dict=results_dict,\n",
    "                        api_key=self.api_key,\n",
    "                        problem=self.problem,\n",
    "                        heuristic_dir=self.heuristic_dir,\n",
    "                        task_description_file=self.task_description_file,\n",
    "                        output_dir=self.output_dir,\n",
    "                        model=self.model\n",
    "                    )\n",
    "                    \n",
    "                    if standalone_smoke_test(file_path, api_key=self.api_key):\n",
    "                        # è¯„ä¼°æ–°å¯å‘å¼\n",
    "                        perf_vector, avg_perf = self.evaluate_heuristic(file_path,time_limit)\n",
    "                        feability = True\n",
    "                        penalty_value = 1e10-1\n",
    "                        for h_each_result in perf_vector:\n",
    "                            if h_each_result > penalty_value:\n",
    "                                feability = False \n",
    "                        if feability:\n",
    "                            print(f\" åŠ å…¥è¯¥æ–°ç®—æ³•: {file_path}\")\n",
    "                            new_heuristics.append({\n",
    "                                'name': file_path,\n",
    "                                'performance_vector': perf_vector,\n",
    "                                'avg_performance': avg_perf\n",
    "                            })\n",
    "                            print(f\"    âœ… CS æˆåŠŸ: {file_path} (avg: {avg_perf:.4f})\")\n",
    "                            self.evaluations += 1\n",
    "                        else:\n",
    "                            print('éœ€è¦è®¡ç®—æ—¶é—´æ•ˆç‡æå‡')\n",
    "                            file_path, code = improve_efficiency(\n",
    "                                                file_path=file_path,\n",
    "                                                api_key=self.api_key,\n",
    "                                                problem=self.problem,\n",
    "                                                heuristic_dir=self.heuristic_dir,\n",
    "                                                task_description_file=self.task_description_file,\n",
    "                                                output_dir=self.output_dir,\n",
    "                                                model=self.model\n",
    "                                            )\n",
    "                            if standalone_smoke_test(file_path, api_key=self.api_key):\n",
    "                                # è¯„ä¼°æ–°å¯å‘å¼\n",
    "                                perf_vector, avg_perf = self.evaluate_heuristic(file_path,time_limit)\n",
    "                              \n",
    "                                feability = True\n",
    "                                penalty_value = 1e10-1\n",
    "                                for h_each_result in perf_vector:\n",
    "                                    if h_each_result > penalty_value:\n",
    "                                        feability = False \n",
    "                                if feability:\n",
    "                                    print(f\" åŠ å…¥è¯¥æ–°ç®—æ³•: {file_path}\")\n",
    "                                    new_heuristics.append({\n",
    "                                        'name': file_path,\n",
    "                                        'performance_vector': perf_vector,\n",
    "                                        'avg_performance': avg_perf\n",
    "                                    })\n",
    "                                    print(f\"    âœ… CS æˆåŠŸ: {file_path} (avg: {avg_perf:.4f})\")\n",
    "                                    self.evaluations += 1\n",
    "                                else:\n",
    "                                    print('æå‡è®¡ç®—æ—¶é—´æ•ˆç‡å¤±è´¥ï¼Œæ”¾å¼ƒè¯¥ç®—æ³•')\n",
    "\n",
    "                            else:\n",
    "                                print(f\"    âŒ LS çƒŸé›¾æµ‹è¯•å¤±è´¥\")\n",
    "                    else:\n",
    "                        print(f\"    âŒ LS çƒŸé›¾æµ‹è¯•å¤±è´¥\")\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    print(f\"    âŒ LS å¤±è´¥: {e}\")\n",
    "            \n",
    "            # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æœ€å¤§è¯„ä¼°æ¬¡æ•°\n",
    "            if self.evaluations >= self.Nmax:\n",
    "                print(f\"\\nâš ï¸  è¾¾åˆ°æœ€å¤§è¯„ä¼°æ¬¡æ•° {self.Nmax}ï¼Œåœæ­¢ç”Ÿæˆ\")\n",
    "                break\n",
    "        \n",
    "        print(f\"\\nğŸ“Š Memetic Search å®Œæˆ: æˆåŠŸç”Ÿæˆ {len(new_heuristics)}/{self.n} ä¸ªæ–°å¯å‘å¼\")\n",
    "        return new_heuristics\n",
    "    \n",
    "    def complementary_population_management(self, \n",
    "                                            current_pop: List[Dict], \n",
    "                                            new_pop: List[Dict]) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        äº’è¡¥ç§ç¾¤ç®¡ç† (CPM)\n",
    "        ä» 2n ä¸ªå€™é€‰ä¸­é€‰æ‹© n ä¸ª\n",
    "        \"\"\"\n",
    "        # åˆå¹¶å€™é€‰æ± : æœ€å¤š 2n ä¸ªå€™é€‰\n",
    "        candidates = current_pop + new_pop\n",
    "        candidate_pool_size = len(candidates)\n",
    "        \n",
    "        print(f\"\\nğŸ” ç§ç¾¤ç®¡ç†: ä» {candidate_pool_size} ä¸ªå€™é€‰ä¸­é€‰æ‹© {self.n} ä¸ª\")\n",
    "        \n",
    "        if not candidates:\n",
    "            print(\"  âš ï¸  å€™é€‰æ± ä¸ºç©ºï¼\")\n",
    "            return current_pop\n",
    "        \n",
    "        m = len(candidates[0]['performance_vector'])  # å®ä¾‹æ•°é‡\n",
    "        \n",
    "        # 1. é€‰æ‹©å¹³å‡æ€§èƒ½æœ€å¥½çš„ä½œä¸ºç¬¬ä¸€ä¸ª\n",
    "        best_candidate = min(candidates, key=lambda h: h['avg_performance'])\n",
    "        selected = [best_candidate]\n",
    "        candidates = [h for h in candidates if h['name'] != best_candidate['name']]\n",
    "        \n",
    "        print(f\"  1ï¸âƒ£  åˆå§‹é€‰æ‹©: {best_candidate['name']} (avg: {best_candidate['avg_performance']:.4f})\")\n",
    "        \n",
    "        # 2. è¿­ä»£é€‰æ‹©å‰©ä½™ n-1 ä¸ªå¯å‘å¼\n",
    "        for step in range(min(self.n - 1, len(candidates))):\n",
    "            if not candidates:\n",
    "                print(f\"  âš ï¸  å€™é€‰æ± å·²ç©ºï¼Œä»…é€‰æ‹©äº† {len(selected)}/{self.n} ä¸ª\")\n",
    "                break\n",
    "            \n",
    "            # è®¡ç®—æ¯ä¸ªå€™é€‰çš„ Delta CPI\n",
    "            best_delta = -np.inf\n",
    "            best_candidate = None\n",
    "            \n",
    "            for candidate in candidates:\n",
    "                delta_cpi = self.compute_delta_cpi(selected, candidate, m)\n",
    "                if delta_cpi > best_delta:\n",
    "                    best_delta = delta_cpi\n",
    "                    best_candidate = candidate\n",
    "            \n",
    "            if best_candidate:\n",
    "                selected.append(best_candidate)\n",
    "                candidates = [h for h in candidates if h['name'] != best_candidate['name']]\n",
    "                print(f\"  {step+2}ï¸âƒ£  é€‰æ‹©: {best_candidate['name']} \"\n",
    "                      f\"(avg: {best_candidate['avg_performance']:.4f}, Î” CPI: {best_delta:.4f})\")\n",
    "        \n",
    "        print(f\"  âœ… æœ€ç»ˆé€‰æ‹© {len(selected)} ä¸ªå¯å‘å¼\")\n",
    "        return selected\n",
    "    \n",
    "    def compute_delta_cpi(self, current_set: List[Dict], candidate: Dict, m: int) -> float:\n",
    "        \"\"\"è®¡ç®—Delta CPI - å…¬å¼(5)\"\"\"\n",
    "        delta = 0.0\n",
    "        \n",
    "        for j in range(m):\n",
    "            # f*_Hk,ij: å½“å‰é›†åˆåœ¨å®ä¾‹jä¸Šçš„æœ€ä½³å¾—åˆ†\n",
    "            f_star = min(h['performance_vector'][j] for h in current_set)\n",
    "            \n",
    "            # fij(candidate): å€™é€‰å¯å‘å¼åœ¨å®ä¾‹jä¸Šçš„å¾—åˆ†\n",
    "            f_candidate = candidate['performance_vector'][j]\n",
    "            \n",
    "            # max(f*_Hk,ij - fij(hi), 0)\n",
    "            delta += max(f_star - f_candidate, 0)\n",
    "        \n",
    "        return delta\n",
    "    \n",
    "    def evaluate_heuristic(self, heuristic_path: str,time_limit) -> Tuple[List[float], float]:\n",
    "        \"\"\"è¯„ä¼°å¯å‘å¼åœ¨æ‰€æœ‰å®ä¾‹ä¸Šçš„æ€§èƒ½\"\"\"\n",
    "        results = run_hyper_heuristic(\n",
    "            problem=self.problem,\n",
    "            heuristic=heuristic_path,\n",
    "            test_data=\"test_data\",\n",
    "            llm_config_file=self.llm_config_file,\n",
    "            heuristic_dir=self.heuristic_dir,\n",
    "            iterations_scale_factor=self.iterations_scale_factor,\n",
    "            result_dir=self.result_dir,\n",
    "            time_limit=time_limit\n",
    "        )\n",
    "        \n",
    "        performance_vector = results\n",
    "        avg_performance = np.mean(performance_vector)\n",
    "        \n",
    "        return performance_vector, avg_performance\n",
    "    \n",
    "    def run(self, initial_results_dict: Dict,time_limit) -> List[Dict]:\n",
    "        \"\"\"ä¸»è¿›åŒ–å¾ªç¯\"\"\"\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"ğŸš€ EoH-S ç®—æ³•å¼€å§‹\")\n",
    "        print(\"=\"*80)\n",
    "        print(f\"é…ç½®: ç§ç¾¤å¤§å°={self.n}, æœ€å¤§è¯„ä¼°æ¬¡æ•°={self.Nmax}\")\n",
    "        \n",
    "        # 1. åˆå§‹åŒ–ç§ç¾¤ P0\n",
    "        population = self.initialize_population(initial_results_dict)\n",
    "        print(f\"\\nâœ“ åˆå§‹åŒ–ç§ç¾¤: {len(population)} ä¸ªå¯å‘å¼\")\n",
    "        \n",
    "        # 2. è¿›åŒ–å¾ªç¯\n",
    "        iteration = 0\n",
    "        while self.evaluations < self.Nmax:\n",
    "            iteration += 1\n",
    "            print(f\"\\n{'='*80}\")\n",
    "            print(f\"ğŸ“ˆ ç¬¬ {iteration} ä»£è¿›åŒ– (å·²è¯„ä¼°: {self.evaluations}/{self.Nmax})\")\n",
    "            print(f\"{'='*80}\")\n",
    "            \n",
    "            # (a) Memetic Search: ç”Ÿæˆ n ä¸ªæ–°å¯å‘å¼\n",
    "            new_heuristics = self.memetic_search(population, initial_results_dict,time_limit)\n",
    "            \n",
    "            # å¦‚æœæ²¡æœ‰ç”Ÿæˆä»»ä½•æ–°å¯å‘å¼ï¼Œæå‰ç»ˆæ­¢\n",
    "            if not new_heuristics:\n",
    "                print(\"\\nâš ï¸  æœªèƒ½ç”Ÿæˆæ–°å¯å‘å¼ï¼Œè¿›åŒ–ç»ˆæ­¢\")\n",
    "                break\n",
    "            \n",
    "            # (b) Population Management: ä» 2n å€™é€‰ä¸­é€‰æ‹© n ä¸ª\n",
    "            # æ³¨æ„ï¼šå½“å‰ç§ç¾¤ n ä¸ª + æ–°ç”Ÿæˆ n ä¸ª = æœ€å¤š 2n ä¸ªå€™é€‰\n",
    "            population = self.complementary_population_management(population, new_heuristics)\n",
    "            \n",
    "            # è®¡ç®—å½“å‰ CPI\n",
    "            current_cpi = self.compute_cpi(population)\n",
    "            print(f\"\\nğŸ“Š å½“å‰ç§ç¾¤ CPI: {current_cpi:.4f}\")\n",
    "            \n",
    "            # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æœ€å¤§è¯„ä¼°æ¬¡æ•°\n",
    "            if self.evaluations >= self.Nmax:\n",
    "                print(f\"\\nâœ… è¾¾åˆ°æœ€å¤§è¯„ä¼°æ¬¡æ•° {self.Nmax}ï¼Œè¿›åŒ–ç»“æŸ\")\n",
    "                break\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"ğŸ‰ EoH-S ç®—æ³•å®Œæˆ!\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        return population\n",
    "    \n",
    "    def compute_cpi(self, population: List[Dict]) -> float:\n",
    "        \"\"\"è®¡ç®—äº’è¡¥æ€§èƒ½æŒ‡æ ‡ (CPI) - å…¬å¼(2)\"\"\"\n",
    "        if not population:\n",
    "            return float('inf')\n",
    "        \n",
    "        m = len(population[0]['performance_vector'])\n",
    "        total = 0.0\n",
    "        \n",
    "        for j in range(m):\n",
    "            # æ¯ä¸ªå®ä¾‹ä¸Šçš„æœ€ä½³å¾—åˆ†\n",
    "            f_star = min(h['performance_vector'][j] for h in population)\n",
    "            total += f_star\n",
    "        \n",
    "        return total / m\n",
    "\n",
    "\n",
    "# ä½¿ç”¨ç¤ºä¾‹\n",
    "def main():\n",
    "    # é…ç½®\n",
    "    problem = \"tsp\"\n",
    "    api_key = \"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\"\n",
    "    model = \"x-ai/grok-code-fast-1\"\n",
    "    heuristic_dir = \"basic_heuristics\"\n",
    "    task_description_file = fr\"\\src\\problems\\{problem}\\task_description.txt\"\n",
    "    output_dir = fr\"\\src\\problems\\{problem}\\heuristics\\basic_heuristics\"\n",
    "    test_data=\"test_data\"\n",
    "    result_dir=\"result\"\n",
    "    iterations_scale_factor=1.0\n",
    "    save_to_file=True\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"ğŸ“‹ æ­¥éª¤ 1: è¯„ä¼°åˆå§‹å¯å‘å¼\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    time_limit = 10*60\n",
    "    \n",
    "    # è¯„ä¼°åˆå§‹å¯å‘å¼\n",
    "    results_dict = evaluate_all_heuristics(\n",
    "        problem=problem,\n",
    "        heuristic_dir=heuristic_dir,\n",
    "        test_data=test_data,\n",
    "        iterations_scale_factor=iterations_scale_factor,\n",
    "        result_dir=result_dir,\n",
    "        save_to_file=save_to_file,\n",
    "        time_limit=time_limit\n",
    "    )\n",
    "    \n",
    "    print(results_dict)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ğŸ“‹ æ­¥éª¤ 2: è¿è¡Œ EoH-S\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # è¿è¡Œ EoH-S\n",
    "    eohs = EoHS(\n",
    "        problem=problem,\n",
    "        api_key=api_key,\n",
    "        heuristic_dir=heuristic_dir,\n",
    "        task_description_file=task_description_file,\n",
    "        output_dir=output_dir,\n",
    "        model = model,\n",
    "        population_size=5,  \n",
    "        max_evaluations=100,\n",
    "        time_limit=time_limit\n",
    "    )\n",
    "    \n",
    "    final_population = eohs.run(results_dict,time_limit)\n",
    "    \n",
    "    # è¾“å‡ºæœ€ç»ˆç»“æœ\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ğŸ“Š æœ€ç»ˆç»“æœ\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"ğŸ¯ æœ€ç»ˆå¯å‘å¼é›†å¤§å°: {len(final_population)}\")\n",
    "    print(f\"ğŸ† æœ€ç»ˆ CPI: {eohs.compute_cpi(final_population):.4f}\")\n",
    "    \n",
    "    print(\"\\nğŸ“‹ æœ€ç»ˆå¯å‘å¼é›†:\")\n",
    "    for i, h in enumerate(final_population, 1):\n",
    "        print(f\"  {i}. {h['name']}\")\n",
    "        print(f\"     å¹³å‡æ€§èƒ½: {h['avg_performance']:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882d5b2e-d734-46c1-8b49-3bb4f1eacca2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
