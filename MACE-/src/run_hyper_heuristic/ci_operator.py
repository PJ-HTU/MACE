"""
CI Operator (Complementary Improvement Operator)
å¯¹åº”MACEè®ºæ–‡çš„CIç®—å­ - Algorithm 2, line 3

æ•´åˆäº†:
- prompt_cs.py çš„æç¤ºè¯ç”Ÿæˆé€»è¾‘
- complete_cs_workflow.py çš„å®Œæ•´å·¥ä½œæµ
"""

import os
from typing import Dict, List, Tuple
from langchain_core.prompts import PromptTemplate
from openai import OpenAI


class CIOperator:
    """
    CI (Complementary Improvement) ç®—å­
    
    è®ºæ–‡å…¬å¼(3): C(h_a, h_b) = min(W_ab, W_ba) / m
    å…¶ä¸­ W_ab = |{i : f_i(h_a) < f_i(h_b)}|
    
    é€‰æ‹©å…·æœ‰äº’è¡¥ä¼˜åŠ¿çš„å¯å‘å¼å¯¹,ç”Ÿæˆèåˆç­–ç•¥çš„æ–°å¯å‘å¼
    """
    
    def __init__(
        self,
        problem: str,
        heuristic_dir: str,
        task_description_file: str,
        output_dir: str,
        api_key: str,
        model: str
    ):
        """
        Args:
            problem: é—®é¢˜ç±»å‹ (tsp, jssp, cvrp, psp)
            heuristic_dir: å¯å‘å¼ä»£ç ç›®å½•
            task_description_file: ä»»åŠ¡æè¿°æ–‡ä»¶è·¯å¾„
            output_dir: è¾“å‡ºç›®å½•
            api_key: LLM APIå¯†é’¥
            model: LLMæ¨¡å‹åç§°
        """
        self.problem = problem
        self.heuristic_dir = heuristic_dir
        self.task_description_file = task_description_file
        self.output_dir = output_dir
        self.api_key = api_key
        self.model = model
        
        # åŠ è½½ä»»åŠ¡æè¿°
        self.task_description = self._load_task_description()
    
    def _load_task_description(self) -> str:
        """åŠ è½½ä»»åŠ¡æè¿°æ–‡ä»¶"""
        if self.task_description_file and os.path.exists(self.task_description_file):
            with open(self.task_description_file, 'r', encoding='utf-8') as f:
                return f.read()
        return ""
    
    def generate(self, results_dict: Dict) -> Tuple[str, str]:
        """
        æ‰§è¡ŒCIç®—å­å®Œæ•´å·¥ä½œæµ
        
        Args:
            results_dict: æ‰€æœ‰å¯å‘å¼çš„æ€§èƒ½ç»“æœ
                æ ¼å¼: {heuristic_name: [score_1, score_2, ...]}
        
        Returns:
            (file_path, code): ç”Ÿæˆçš„å¯å‘å¼æ–‡ä»¶è·¯å¾„å’Œä»£ç 
        """
        print("\n" + "=" * 80)
        print("ğŸ” [CIç®—å­] Complementary Improvement å¼€å§‹")
        print("=" * 80)
        
        # Step 1: é€‰æ‹©äº’è¡¥å¯¹ (è®ºæ–‡å…¬å¼3)
        h1_name, h2_name = self._select_complementary_pair(results_dict)
        print(f"âœ“ é€‰æ‹©çš„äº’è¡¥å¯¹: {h1_name} å’Œ {h2_name}")
        
        # Step 2: åŠ è½½å¯å‘å¼ä»£ç 
        h1_code = self._load_heuristic_code(h1_name)
        h2_code = self._load_heuristic_code(h2_name)
        
        # Step 3: ç”ŸæˆCIæç¤ºè¯
        ci_prompt = self._create_ci_prompt(h1_name, h1_code, h2_name, h2_code)
        
        # Step 4: è°ƒç”¨LLMç”Ÿæˆæ–°å¯å‘å¼
        llm_response = self._call_llm(ci_prompt)
        
        # Step 5: æå–ä»£ç 
        extracted_code = self._extract_code_from_response(llm_response)
        
        if not extracted_code:
            print("âœ— æœªèƒ½ä»å“åº”ä¸­æå–ä»£ç ")
            print("\nå®Œæ•´å“åº”:")
            print(llm_response)
            return None, None
        
        # Step 6: ä¿å­˜ä»£ç 
        try:
            file_path = self._save_generated_heuristic(extracted_code)
            
            # ä¿å­˜å®Œæ•´å“åº”ï¼ˆåŒ…æ‹¬æ€è€ƒè¿‡ç¨‹ï¼‰
            response_file = file_path.replace('.py', '_full_response.txt')
            with open(response_file, 'w', encoding='utf-8') as f:
                f.write(f"Prompt used:\n{'-'*80}\n{ci_prompt}\n\n")
                f.write(f"LLM Response:\n{'-'*80}\n{llm_response}")
            
            print(f"âœ“ ä»£ç å·²ä¿å­˜åˆ°: {file_path}")
            
        except Exception as e:
            print(f"âœ— ä¿å­˜å¤±è´¥: {str(e)}")
            return None, extracted_code
        
        # å®Œæˆ
        print("\n" + "=" * 80)
        print("âœ… [CIç®—å­] å·¥ä½œæµå®Œæˆ!")
        print("=" * 80)
        print(f"ğŸ“ ç”Ÿæˆçš„å¯å‘å¼ä»£ç : {file_path}")
        print(f"ğŸ“„ å®Œæ•´å“åº”è®°å½•: {response_file}")
        print(f"ğŸ”¬ åŸºäºäº’è¡¥å¯¹: {h1_name} + {h2_name}")
        print("=" * 80 + "\n")
        
        return file_path, extracted_code
    
    def _select_complementary_pair(self, results_dict: Dict) -> Tuple[str, str]:
        """
        é€‰æ‹©äº’è¡¥å¯¹ - è®ºæ–‡å…¬å¼(3)
        
        C(h_a, h_b) = min(W_ab, W_ba) / m
        å…¶ä¸­ W_ab = |{i : f_i(h_a) < f_i(h_b)}|
        """
        # å¯¼å…¥è¾…åŠ©å‡½æ•°
        from src.run_hyper_heuristic.helper_function import select_complementary_pair
        return select_complementary_pair(results_dict)
    
    def _load_heuristic_code(self, heuristic_name: str) -> str:
        """åŠ è½½å¯å‘å¼ä»£ç """
        from src.run_hyper_heuristic.helper_function import load_heuristic_code
        return load_heuristic_code(self.problem, heuristic_name, self.heuristic_dir)
    
    def _create_ci_prompt(
        self,
        h1_name: str,
        h1_code: str,
        h2_name: str,
        h2_code: str
    ) -> str:
        """
        åˆ›å»ºCIæç¤ºè¯
        """
        prompt_template = PromptTemplate(
            input_variables=[
                "task_description",
                "heuristic1_name",
                "heuristic1_code",
                "heuristic2_name",
                "heuristic2_code"
            ],
            template="""# Problem Context

{task_description}

# Task: Design a New Complementary Heuristic Algorithm

You are an expert in designing heuristic algorithms for combinatorial optimization problems.

I have 2 existing heuristic algorithms that show complementary performance across different problem instances:

## Heuristic Algorithm 1: {heuristic1_name}
```python
{heuristic1_code}
```

## Heuristic Algorithm 2: {heuristic2_name}
```python
{heuristic2_code}
```

## Your Task

These two algorithms are effective for solving different instance distributions. Please design a NEW heuristic algorithm that:

1. **Synthesizes complementary strengths** - Integrate effective decision patterns from both algorithms
2. **Is distinct** from the two provided algorithms
3. **Improves instance-level coverage** - Handle cases where both algorithms underperform
4. **Explores new strategies** or combine their strengths in innovative ways

**IMPORTANT CODE FORMAT REQUIREMENTS:**

1. The function name must follow the pattern: `<strategy_name>_<random_4_chars>` (e.g., `hybrid_greedy_a3f7`)
2. Follow the exact code format shown in the examples above
3. Ensure your code is complete and executable

**Response Format:**

The response format is very important. Please respond in this format:

***python_code:
[Your complete Python code here]
***

**CRITICAL:** 
- Ensure there is no other content inside the ***
- Analysis and explanation outside *** are welcome
- The code must be complete and runnable

Please provide your new heuristic algorithm now:"""
        )
        
        # ç”Ÿæˆæœ€ç»ˆæç¤ºè¯
        final_prompt = prompt_template.format(
            task_description=self.task_description,
            heuristic1_name=h1_name,
            heuristic1_code=h1_code,
            heuristic2_name=h2_name,
            heuristic2_code=h2_code
        )
        
        return final_prompt
    
    def _call_llm(self, prompt: str) -> str:
        """è°ƒç”¨LLMç”Ÿæˆä»£ç """
        client = OpenAI(
            api_key=self.api_key,
            base_url="https://openrouter.ai/api/v1"  # OpenAI SDKä¼šè‡ªåŠ¨æ·»åŠ /chat/completions
        )
        
        try:
            response = client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": "You are an expert algorithm designer for combinatorial optimization problems."
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                temperature=0.7
            )
            
            llm_response = response.choices[0].message.content
            return llm_response
            
        except Exception as e:
            print(f"âœ— APIè°ƒç”¨å¤±è´¥: {str(e)}")
            raise
    
    def _extract_code_from_response(self, response: str) -> str:
        """ä»LLMå“åº”ä¸­æå–ä»£ç """
        from src.run_hyper_heuristic.helper_function import extract_code_from_response
        return extract_code_from_response(response)
    
    def _save_generated_heuristic(self, code: str) -> str:
        """ä¿å­˜ç”Ÿæˆçš„å¯å‘å¼ä»£ç """
        from src.run_hyper_heuristic.helper_function import save_generated_heuristic
        return save_generated_heuristic(code, output_dir=self.output_dir)


# ä¾¿æ·å‡½æ•° - ä¿æŒä¸åŸæ¥complete_cs_workflowçš„å…¼å®¹æ€§
def complete_cs_workflow(
    results_dict: Dict,
    api_key: str,
    problem: str,
    heuristic_dir: str,
    task_description_file: str,
    output_dir: str,
    model: str
) -> Tuple[str, str]:
    """
    CIå·¥ä½œæµ - å‘åå…¼å®¹çš„ä¾¿æ·å‡½æ•°
    
    Args:
        results_dict: æ‰€æœ‰å¯å‘å¼çš„æ€§èƒ½ç»“æœ
        api_key: LLM APIå¯†é’¥
        problem: é—®é¢˜ç±»å‹
        heuristic_dir: å¯å‘å¼ç›®å½•
        task_description_file: ä»»åŠ¡æè¿°æ–‡ä»¶è·¯å¾„
        output_dir: è¾“å‡ºç›®å½•
        model: LLMæ¨¡å‹åç§°
    
    Returns:
        (file_path, code): ç”Ÿæˆçš„å¯å‘å¼æ–‡ä»¶è·¯å¾„å’Œä»£ç 
    """
    operator = CIOperator(
        problem=problem,
        heuristic_dir=heuristic_dir,
        task_description_file=task_description_file,
        output_dir=output_dir,
        api_key=api_key,
        model=model
    )
    
    return operator.generate(results_dict)